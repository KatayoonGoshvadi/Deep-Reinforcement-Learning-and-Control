{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O3lRSKm9LZFQ"
   },
   "source": [
    "# 10-703: Homework 1 - Behavior Cloning, DAGGER, CMA-ES, and GAIL\n",
    "\n",
    "You will implement this assignment right here in this Colab notebook. Colab is a Jupyter notebook that runs in the cloud. If you haven't used Colab before, we recommend checking out the following tutorial:\n",
    "https://colab.sandbox.google.com/notebooks/welcome.ipynb.\n",
    "Note that all cells modify the same global state, so imported packages as well as functions and variables declared in one cell will be accessible in other cells.\n",
    "\n",
    "\n",
    "To get started, click the ``Open in Playground`` button in the upper right. Then click the ``Copy to Drive`` button in the upper center to save a copy in your Google drive. In the future, you will be able to find the notebook by looking in your Google drive folder.\n",
    "\n",
    "Now, you're ready start coding. You will want to run each cell in this notebook by clicking the \"play\" button to the left of the cell (or using [ctrl -> enter]. Look for ``WRITE CODE HERE'' to identify places where you need to write some code. Each section involves writing 3 - 10 lines of code. \n",
    "\n",
    "When you're done, copy plots genetated by your code into the solution boxes in the submission LaTeX file released with this assignment. In addition to uploading your PDF submission to GradeScope (one per group), you should also upload your code. To do this, explort the code from this notebook (File -> Export.py), and then upload the .py file to GradeScope.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HDrq4jSWWYx1"
   },
   "source": [
    "# Preliminaries\n",
    "In these first few cells, you will implement some compoments that will be used for all problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WIXzVYlFLL-m"
   },
   "source": [
    "\n",
    "### Setup: Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MgHGKD-_iB3r",
    "outputId": "54e18242-9b69-43bb-d669-27d81671015c"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict \n",
    "import gym\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import subprocess \n",
    "import random\n",
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5YiASXZnSH7C"
   },
   "source": [
    "### Make the TF Model\n",
    "We'll use the same architecture for each of the problems. By implementing a function that creates the model here, you won't need to implement it again for each problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cr7A-CqASErb"
   },
   "outputs": [],
   "source": [
    "def make_model(input_shape):\n",
    "    model = Sequential()      \n",
    "    # WRITE CODE HERE\n",
    "    # Add layers to the model:  \n",
    "    # a fully connected layer with 10 units\n",
    "    # a tanh activation\n",
    "    # another fully connected layer with 2 units (the number of actions)\n",
    "    # a softmax activation (so the output is a proper distribution)\n",
    "\n",
    "    model.add(Dense(10, input_dim=input_shape))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    model.add(Dense(2, input_dim=10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer=tf.train.AdamOptimizer(),\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "    # We expect the model to have four weight variables (a kernel and bias for\n",
    "    # both layers)\n",
    "    assert len(model.weights) == 4, 'Model should have 4 weights.'\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c0z4oMxZSgq6"
   },
   "source": [
    "### Test the model\n",
    "To confirm that the model is correct, we'll use it to solve a binary classification problem. The target function $f: \\mathbb{R}^4 \\rightarrow {0, 1}$ indicates whether the sum of the vector coordinates is positive:\n",
    "$$f(x) = \\delta \\left(\\sum_{i=1}^4 x_i > 0 \\right)$$\n",
    "\n",
    "You should achieve an accuracy of at least 98%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "colab_type": "code",
    "id": "Y1iJByvzSp7_",
    "outputId": "e1f2cd13-464d-4561-9654-fb05a57f463f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0) loss= 0.332; accuracy = 95.2%\n",
      "(1) loss= 0.265; accuracy = 97.3%\n",
      "(2) loss= 0.236; accuracy = 97.9%\n",
      "(3) loss= 0.202; accuracy = 98.7%\n",
      "(4) loss= 0.181; accuracy = 98.6%\n",
      "(5) loss= 0.158; accuracy = 99.8%\n",
      "(6) loss= 0.145; accuracy = 99.4%\n",
      "(7) loss= 0.131; accuracy = 99.3%\n",
      "(8) loss= 0.122; accuracy = 99.0%\n",
      "(9) loss= 0.115; accuracy = 99.5%\n",
      "(10) loss= 0.107; accuracy = 99.6%\n",
      "(11) loss= 0.103; accuracy = 99.3%\n",
      "(12) loss= 0.094; accuracy = 99.5%\n",
      "(13) loss= 0.083; accuracy = 99.8%\n",
      "(14) loss= 0.078; accuracy = 99.3%\n",
      "(15) loss= 0.071; accuracy = 99.7%\n",
      "(16) loss= 0.076; accuracy = 99.8%\n",
      "(17) loss= 0.073; accuracy = 99.3%\n",
      "(18) loss= 0.070; accuracy = 99.5%\n",
      "(19) loss= 0.065; accuracy = 99.7%\n"
     ]
    }
   ],
   "source": [
    "model = make_model(input_shape=4)\n",
    "for t in range(20):\n",
    "    X = np.random.normal(size=(1000, 4))  # some random data\n",
    "    is_positive = np.sum(X, axis=1) > 0  # A simple binary function\n",
    "    Y = np.zeros((1000, 2))\n",
    "    Y[np.arange(1000), is_positive.astype(int)] = 1  # one-hot labels\n",
    "    history = model.fit(X, Y, epochs=10, batch_size=256, verbose=0)\n",
    "    loss = history.history['loss'][-1]\n",
    "    acc = history.history['accuracy'][-1]\n",
    "    print('(%d) loss= %.3f; accuracy = %.1f%%' % (t, loss, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sw_HvyFnWXa5"
   },
   "source": [
    "### Interacting with the Gym\n",
    "Implement the function below for gathering an episode (a \"rollout\"). The environment we will use will implement the OpenAI Gym interface. For documentation, please see the link below:\n",
    "http://gym.openai.com/docs/#environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmRoHiliWdJf"
   },
   "outputs": [],
   "source": [
    "def action_to_one_hot(env, action):\n",
    "    action_vec = np.zeros(env.action_space.n)\n",
    "    action_vec[action] = 1\n",
    "    return action_vec    \n",
    "  \n",
    "def disc_action_to_one_hot(disc_classes, action):\n",
    "    action_vec = np.zeros(disc_classes)\n",
    "    action_vec[action] = 1\n",
    "    return action_vec    \n",
    "          \n",
    "def generate_episode(env, policy):\n",
    "    \"\"\"Collects one rollout from the policy in an environment. The environment\n",
    "    should implement the OpenAI Gym interface. A rollout ends when done=True. The\n",
    "    number of states and actions should be the same, so you should not include\n",
    "    the final state when done=True.\n",
    "\n",
    "    Args:\n",
    "    env: an OpenAI Gym environment.\n",
    "    policy: a keras model\n",
    "    Returns:\n",
    "    states: a list of states visited by the agent.\n",
    "    actions: a list of actions taken by the agent. While the original actions\n",
    "      are discrete, it will be helpful to use a one-hot encoding. The actions\n",
    "      that you return should be one-hot vectors (use action_to_one_hot())\n",
    "    rewards: the reward received by the agent at each step.\n",
    "    \"\"\"\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    while not done:\n",
    "      # WRITE CODE HERE\n",
    "        states.append(state)\n",
    "        action = np.argmax(policy.predict(np.expand_dims(state,axis=0)))\n",
    "        actions.append(action_to_one_hot(env, action))\n",
    "        state, reward, done, info = env.step(action)\n",
    "        rewards.append(reward)\n",
    "\n",
    "    return np.array(states), np.array(actions), np.array(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9mCrbZDXVvI"
   },
   "source": [
    "### Test the data collection\n",
    "Run the following cell and make sure you see \"Test passed!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WCo0B_aDXZfX",
    "outputId": "583010b7-f476-4c4e-ecf6-b4bce6a668cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# Create the environment.\n",
    "env = gym.make('CartPole-v0')\n",
    "policy = make_model(env.observation_space.shape[0])\n",
    "states, actions, rewards = generate_episode(env, policy)\n",
    "assert len(states) == len(actions), 'Number of states and actions should be equal.'\n",
    "assert len(actions) == len(rewards), 'Number of actions and rewards should be equal.'\n",
    "assert len(actions[0]) == 2, 'Actions should use one-hot encoding.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k5GAtN56n9hk"
   },
   "source": [
    "### Download the expert policy\n",
    "Click on the link below to download the expert policy (`expert.h5`):\n",
    "https://drive.google.com/uc?export=download&id=1n62yCdr_gfvvoWISpiz-RuM_TttxEjcq\n",
    "\n",
    "In the left pane, navigate to the \"Files\" tab, and upload the `expert.h5` file. Run the cell below to confirm that the correct file has been uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "91G9CWHJtVdR",
    "outputId": "ed0ce066-5977-4567-e74f-6e598b847add"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-09-19 14:36:04--  https://raw.githubusercontent.com/cmudeeprl/703website/master/assets/homework/hw1/expert.h5\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.248.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.248.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 44536 (43K) [application/octet-stream]\n",
      "Saving to: ‘expert.h5’\n",
      "\n",
      "expert.h5           100%[===================>]  43.49K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2019-09-19 14:36:04 (1.23 MB/s) - ‘expert.h5’ saved [44536/44536]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/cmudeeprl/703website/master/assets/homework/hw1/expert.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w8mAIl5xLc6e"
   },
   "source": [
    "## Problem 1: Behavior Cloning and DAGGER (50 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oYIziDr-VUG7"
   },
   "source": [
    "### Implementing Behavior Cloning and DAGGER\n",
    "To implement behavior cloning and DAGGER, fill in the missing blocks of code below. The provided code loads an expert model upon creation of the `Imitation` class. The function `generate_behavior_cloning_data()` fills in `self._train_states` and `self._train_actions` with states and actions from a single episode. Later, when implementing DAGGER, you will finish implementing `generate_dagger_data()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qn2jQXBNh2WQ"
   },
   "outputs": [],
   "source": [
    "class Imitation():\n",
    "\n",
    "    def __init__(self, env, num_episodes):\n",
    "        self.env = env\n",
    "        self.expert = tf.keras.models.load_model('expert.h5')\n",
    "        self.num_episodes = num_episodes\n",
    "        \n",
    "        \n",
    "        self.model = make_model(self.env.observation_space.shape[0])\n",
    "        \n",
    "    def generate_behavior_cloning_data(self):\n",
    "        self._train_states = []\n",
    "        self._train_actions = []\n",
    "        for _ in range(self.num_episodes):\n",
    "            states, actions, rewards = generate_episode(self.env, self.expert)\n",
    "            self._train_states.extend(states)\n",
    "            self._train_actions.extend(actions)\n",
    "        self._train_states = np.array(self._train_states)\n",
    "        self._train_actions = np.array(self._train_actions)\n",
    "        \n",
    "    def generate_dagger_data(self):\n",
    "        # WRITE CODE HERE\n",
    "        # You should collect states and actions from the student policy\n",
    "        # (self.model), and then relabel the actions using the expert policy.\n",
    "        # This method does not return anything.\n",
    "        self._train_states = []\n",
    "        self._train_actions = []\n",
    "        for _ in range(self.num_episodes):\n",
    "            states, actions, rewards = generate_episode(self.env, self.model)\n",
    "            self._train_states.extend(states)\n",
    "            self._train_actions.extend(actions)\n",
    "            \n",
    "        for state_id,state in enumerate(self._train_states):\n",
    "            self._train_actions[state_id] = action_to_one_hot(self.env,np.argmax(self.expert.predict(np.expand_dims(state,axis=0))))\n",
    "          \n",
    "        self._train_states = np.array(self._train_states)\n",
    "        self._train_actions = np.array(self._train_actions)\n",
    "        \n",
    "    def train(self, num_epochs=200, render=False):\n",
    "        \"\"\"Trains the model on training data generated by the expert policy.\n",
    "        Args:\n",
    "          env: The environment to run the expert policy on.\n",
    "          num_epochs: number of epochs to train on the data generated by the expert.\n",
    "          render: Whether to render the environment.\n",
    "        Return:\n",
    "          loss: (float) final loss of the trained policy.\n",
    "          acc: (float) final accuracy of the trained policy\n",
    "        \"\"\"\n",
    "        # WRITE CODE HERE\n",
    "        \n",
    "        history = self.model.fit(self._train_states,self._train_actions, epochs=num_epochs) # batch_size=256, verbose=0\n",
    "        loss = history.history['loss'][-1]\n",
    "        acc = history.history['accuracy'][-1]\n",
    "        return loss, acc\n",
    "\n",
    "\n",
    "    def evaluate(self, policy, n_episodes=50):\n",
    "        rewards = []\n",
    "        for i in range(n_episodes):\n",
    "            _, _, r = generate_episode(self.env, policy)\n",
    "            rewards.append(sum(r))\n",
    "        r_mean = np.mean(rewards)\n",
    "        return r_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vu7FcPOkAz-c"
   },
   "source": [
    "### Experiment: Student vs Expert\n",
    "In the next two cells, you will compare the performance of the expert policy\n",
    "to the imitation policies obtained via behavior cloning and DAGGER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sRMPf6r2itw3",
    "outputId": "07127335-4c31-49a7-a96b-173e5d0c8bdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert reward: 200.00\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 0.4678 - accuracy: 0.7856\n",
      "(0) loss = 0.468; accuracy = 0.79; reward = 83.2\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 0s 19us/step - loss: 0.3216 - accuracy: 0.8296\n",
      "(1) loss = 0.322; accuracy = 0.83; reward = 157.5\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 0.2957 - accuracy: 0.8426\n",
      "(2) loss = 0.296; accuracy = 0.84; reward = 179.9\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 0s 21us/step - loss: 0.2795 - accuracy: 0.8539\n",
      "(3) loss = 0.279; accuracy = 0.85; reward = 192.3\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 0s 18us/step - loss: 0.2633 - accuracy: 0.8662\n",
      "(4) loss = 0.263; accuracy = 0.87; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 0s 17us/step - loss: 0.2502 - accuracy: 0.8767\n",
      "(5) loss = 0.250; accuracy = 0.88; reward = 200.0\n"
     ]
    }
   ],
   "source": [
    "# Uncomment one of the two lines below to select whether to run behavior\n",
    "# cloning or dagger\n",
    "mode = 'behavior cloning'\n",
    "# mode = 'dagger'\n",
    "\n",
    "num_episodes = 100  # Leave this fixed for now. You will experiment with\n",
    "                    # changing it later.\n",
    "num_iterations = 100  # Number of training iterations. Use a small number\n",
    "                     # (e.g., 10) for debugging, and then try a larger number\n",
    "                     # (e.g., 100).\n",
    "\n",
    "# Create the environment.\n",
    "env = gym.make('CartPole-v0')\n",
    "im = Imitation(env, num_episodes)\n",
    "expert_reward = im.evaluate(im.expert)\n",
    "print('Expert reward: %.2f' % expert_reward)\n",
    "\n",
    "loss_vec = []\n",
    "acc_vec = []\n",
    "imitation_reward_vec = []\n",
    "for t in range(num_iterations):\n",
    "    if mode == 'behavior cloning':\n",
    "        im.generate_behavior_cloning_data()\n",
    "    elif mode == 'dagger':\n",
    "        im.generate_dagger_data()\n",
    "    else:\n",
    "        raise ValueError('Unknown mode: %s' % mode)\n",
    "    loss, acc = im.train(num_epochs=1)\n",
    "    imitation_reward = im.evaluate(im.model)\n",
    "    loss_vec.append(loss)\n",
    "    acc_vec.append(acc)\n",
    "    imitation_reward_vec.append(imitation_reward)\n",
    "    print('(%d) loss = %.3f; accuracy = %.2f; reward = %.1f' % (t, loss, acc, imitation_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wacKZfLU1oAC"
   },
   "source": [
    "### Plot the results\n",
    "After saving your plots by running `plt.savefig(FILENAME)`, you can download them by navigating to the `Files` tab on the left, and then right-clicking on each filename and selecting `Download`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "fcytZUZYmrzc",
    "outputId": "ef591c6c-7cb5-443a-e606-8ee006b9a718"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAADQCAYAAAAalMCAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd0FeX28PHvTg9JCJCEGrqhhA6h\nCQqCICqKBSsqWLAj99rQn1719eq112tBVMSKIipysaJSVEAIvQkEpCTUAAFCerLfP2YSDxBIgJwc\nkuzPWrM455ln5uxhyTh7niaqijHGGGOMMcaYk+fn6wCMMcYYY4wxprKwBMsYY4wxxhhjyoglWMYY\nY4wxxhhTRizBMsYYY4wxxpgyYgmWMcYYY4wxxpQRS7CMMcYYY4wxpoxYgmUqBRGZICJP+DoOY4wx\nxhhTtVmCZUokIhtFJFNE0kVku5vMhPs6LmOMgaJ71Nm+jsMYU/GJyEwR2Ssiwb6OxVRclmCZ0rpA\nVcOBjkAn4EFfBCEiAb74XWOMMcZUbiLSBDgDUODCcvxde7apZCzBMsdFVbcDP+AkWohIsIg8LyKb\nRWSHiIwVkVB33ywRudT93EtEVETOd7/3F5El7ufmIvKLiOwWkVQR+VhEahT+pvt2eoyILAMOikiA\niHQSkUUickBEPgNCyvdvwhhzqhORkSKSJCJ7RGSqiNR3y0VEXhKRnSKyX0SWi0hbd995IrLKvbek\niMi9vr0KY0w5ug6YB0wAhhcWikioiLwgIptEZJ+I/ObxrNNbROaISJqIbBGREW75TBG5yeMcI0Tk\nN4/vKiJ3iMg6YJ1b9op7jv0islBEzvCo7y8i/yci693700IRaSgir4vIC54X4d7v/umNvyBTOpZg\nmeMiIrHAuUCSW/Q00AIn4ToNaAA84u6bBfR1P/cBNgBnenyfVXha4CmgPtAaaAg8dthPXwWcD9TA\n+e92CvAhUAv4HLj05K/OGFNZiEg/nPvK5UA9YBPwqbt7IM69qAUQ6dbZ7e57F7hFVSOAtsAv5Ri2\nMca3rgM+drdzRKSOW/480AU4Hee5436gQEQaA98B/wVicJ6FlhzH710EdAfi3e8L3HPUAj4BPheR\nwhfId+M8C50HVAduADKA94GrRMQPQESigbPd442PWIJlSmuKiBwAtgA7gUdFRICbgX+q6h5VPQD8\nB7jSPWYWTiIFzsPMUx7fixIsVU1S1emqmq2qu4AXPeoVelVVt6hqJtADCAReVtVcVZ2Mc1MyxphC\nw4DxqrpIVbNxujX3dLsA5QIRQCtAVHW1qm5zj8sF4kWkuqruVdVFPojdGFPORKQ30BiYpKoLgfXA\n1W7icgMwWlVTVDVfVee495WrgZ9UdaL7PLJbVY8nwXrKfX7KBFDVj9xz5KnqC0Aw0NKtexPwsKqu\nUcdSt+58YB/Q3613JTBTVXec5F+JOQmWYJnSush9o9sX56EkGudtTTVgods0ngZ875YDzAVauG+A\nOgIfAA3dtyvdgNkAIlJHRD51u+PsBz5yz+9pi8fn+kCKqqpH2aayu1RjTCVQH4/7gqqm47RSNVDV\nX4DXgNeBnSIyTkSqu1UvxXlDvMnt5tyznOM2xvjGcOBHVU11v3/ilkXjDENYX8wxDY9SXlqezzaI\nyL0istrthpiG08Je+Dx0rN96H7jG/XwNTg8f40OWYJnjoqqzcPomPw+kAplAG1Wt4W6R7mQYqGoG\nsBAYDaxQ1RxgDk4z93qPm9h/cAaUtlPV6jg3Bzn8pz0+bwMauC1ohRqV4WUaYyq+rThvowEQkTAg\nCkgBUNVXVbULTtecFsB9bvkCVR0C1MbpijypnOM2xpQzdzzV5UAfd7bk7cA/gQ44XYyzgObFHLrl\nKOUAB3FeQheqW0ydomcbd7zV/W4cNVW1Bk7LVOGzzrF+6yNgiIh0wBlqMeUo9Uw5sQTLnIiXgQFA\nO+Bt4CURqQ0gIg1E5ByPurOAO/l7vNXMw76D01UnHdgnIg1wH3SOYS6QB9wlIoEicglOi5gxpuoK\nFJGQwg2YCFwvIh3FmW75P8AfqrpRRLqKSHcRCcR5CMrCGU8RJCLDRCRSVXOB/UCBz67IGFNeLgLy\ncV64dHS31sCvOOOyxgMvikh9d7KJnu595WPgbBG53J2AK0pEOrrnXAJcIiLVROQ04MYSYojAebbZ\nBQSIyCM4Y60KvQP8W0Ti3Il62otIFICqJuMMlfgQ+KKwy6HxHUuwzHFzx0l9gDOZxRicCS/mud37\nfuLv/sLgJFIRuN0Bi/kO8P+Azjhvar4Bvizh93OAS4ARwB7gipKOMcZUet/itKgXbn2BfwFf4LR6\nN+fv8aHVcV4O7cXpRrgbeM7ddy2w0b2f3YozlssYU7kNB95T1c2qur1ww+lKPAx4AFiOk8TsAZ4B\n/FR1M06X4nvc8iU4rV4ALwE5wA6cLnwflxDDDzjDLNbi3JeyOLQL4Ys4Leo/4rz8eRcI9dj/Ps6L\nb+seeAqQQ4exGGOMMcYYYyoSETkTp6tgY7WHe5+zFixjjDHGGGMqKLe782jgHUuuTg2WYBljjDHG\nGFMBiUhrIA1nMo6XfRyOcVkXQWOMMcYYY4wpI15rwRKRhiIyQ0RWichKERntltcSkekiss79s6Zb\nLiLyqogkicgyEensrdiMMcYYY4wxxhu81oIlIvWAeqq6SEQicNZDugh35jdVfVpEHsCZ63+MiJwH\njMKZjaU78Iqqdj/Wb0RHR2uTJk28Er8x5tgWLlyYqqoxJdesnOz+Y4xv2L3H7j3G+Epp7z8B3gpA\nVbfhTI2Lqh4QkdVAA2AIzvS54EwpORNnqu8hwAfu4Lx5IlJDROq55ylWkyZNSExMLDGWvn37HlGW\nF1Sd1GYDUT//47gqYyqv6tsXE7ZnLTNnzixVfRHZ5N2ITm2lvf8YY8qW3Xvs3mOMr5T2/lMuk1yI\nSBOgE/AHUMcjadoO1HE/N+DQ+f6T3bLDz3WziCSKSOKuXbtOOKa02J5kVW94wscbY4wxxhhjzOG8\n1oJVSETCcRZ6/Ieq7heRon2qqiJyXH0UVXUcMA4gISGhVMce/kZ+y54Mznp+JiN6NOaxC4ccz88b\nY4wxxhhjzFF5tQXLnZf/C+BjVf3SLd7hjs8qHKe10y1PATyblGLdsjI3dtZ6/ES4pU8zb5zeGGOM\nMcYYU0V5rQVLnKaqd4HVqvqix66pwHDgaffPrz3K7xSRT3Emudh3rPFXJ2rH/iw+T0xmaEIs9SJD\ny/r05hSUm5tLcnIyWVlZvg6lQgoJCSE2NpbAwEBfh2KMMcYYc8rzZhfBXsC1wHIRWeKW/R9OYjVJ\nRG4ENgGXu/u+xZlBMAnIAK73RlDzNuwmJ7+Aa7o39sbpzSkoOTmZiIgImjRpgmcXVVMyVWX37t0k\nJyfTtGlTX4dT4bz44xqCA/2546zTfB2KMcYYUyXl5ReQV6CIwPLkfczbsJvTakcwML4OB7LyeGv2\nemIigrm+V9k953hzFsHfgKM9zfYvpr4Cd3grnkK7DmQD0KCGtV5VFVlZWZZcnSARISoqipOZUKYq\nm7thNwF+fpZgGVMJiMgg4BXAH3hHVZ8+bH9jYDwQA+wBrlHVZBE5C3jJo2or4EpVnSIiE4A+wD53\n3whVXYIx5rhk5ebz67pU+rSIISjg7xFQG1MPcvlbc9npPv97ah4Txq4D2RzIzivzhhevT3JxqklN\nzyHQX6geWuUuvUqz5OrE2d/diasWFEBaRo6vwzDGnCQR8QdeBwbgzHK8QESmquoqj2rP4yw3876I\n9AOeAq5V1RlAR/c8tXB66vzocdx9qjq5PK7DmIru+xXbmDBnI6P6xdHrtGgKCpTpq3fwxDer2LIn\nk9v6NmfMoFYAZObkc+tHC8nJL+C+c1qSl6+0qBNO92ZR/LpuF+/9vpFmMeHcPaAFretVL9M4q1yW\nsTs9m6iwYHtoNMZ4XViwPylp+b4Owxhz8roBSaq6AcAdLz4E8Eyw4oG73c8zgCnFnGco8J2qZngx\nVmMqnPwCJWlnOn+lpuPv50ffljEIMHH+ZuZu2E3P5tHsSc/hpZ/WEhTgx7B3/uCsljH8uf0A2/Zl\nEVc7nD4tYnh79gaGdKzPaTHhPPjlMtbsOMB7I7rSt2XtQ35vSMcGDOl4xGpQZabKJVip6dlERwT5\nOgxTxZx++unMmTOn1PXHjh1LtWrVuO6665gwYQIDBw6kfv36xzzm8Ho33XQTd999N/Hx8ScVuzlx\noYEBZOZYgmVMJVDcWp3dD6uzFLgEpxvhxUCEiESp6m6POlcCLx523JMi8gjwM/CAqh7Rl0lEbgZu\nBmjUqNHJXIcxp5zMnHxumLCAuRv+/qdSOyKYGtUCWbsjnVphQXy7fDsAQzrW5/EL2/LGrCQmLdhC\nl8Y1eeDcVpzXrh7pWXn0f3EW936+FIAVKfu5Z0CLI5Kr8lAFE6wcosODfR2GqWKOJ7kCuPXWW4s+\nT5gwgbZt25YqwfKs98477xx/oKZMhQX7czAnz9dhGGPKx73AayIyApiNs9RM0RsWd2madsAPHsc8\nCGwHgnDW+BwDPH74iU9kDVBjThWqyqTELWzZk0nT6DBqhgUiCBEhAcTWrMZ9k5cy76/d/N95rejZ\nLJqdB7L4YO4mtu/L4o1hnTm3bV2SdqazfX8WvU+LRkR48NzWPHhu60N+p2ZYEA+d15p7Pl9KTERw\n0bG+UAUTrGxa1o3wdRimigkPDyc9PZ2ZM2fy6KOPUqNGDZYvX87ll19Ou3bteOWVV8jMzGTKlCk0\nb96cxx57jPDwcJo0aUJiYiLDhg0jNDSUuXPn8txzz/G///2PzMxMTj/9dN566y2++OKLI+qde+65\nPP/88yQkJDBx4kT+85//oKqcf/75PPPMM0VxjR49mmnTphEaGsrXX39NnTp1fPy3VfZKGpzuUe9S\nYDLQVVUTT/Z3Q4P8ybAWLGMqgxLX6lTVrTgtWIhIOHCpqqZ5VLkc+EpVcz2OKVyOJltE3sNJ0oyp\nkFZu3ce9ny/j0s4NuOkMZ63ZnLwC/u+r5UxemIwI6FFeDzw3tD2XJRT+E4ukf+tDn0Xi6kQQV6fk\n5/dLOjcgOiKYjg1rEBnqu+VlqlSCparsthasKu3//W8lq7buL9NzxtevzqMXtCl1/aVLl7J69Wpq\n1apFs2bNuOmmm5g/fz6vvPIK//3vf3n55ZeL6g4dOpTXXnutKFECuPPOO3nkkUcAuPbaa5k2bVqx\n9Qpt3bqVMWPGsHDhQmrWrMnAgQOZMmUKF110EQcPHqRHjx48+eST3H///bz99ts8/PDDZfC3cuoo\n5eB0RCQCGA38UVa/HRYUQE5eAbn5BQT6e3Vdd2OMdy0A4kSkKU5idSVwtWcFEYkG9qhqAU7L1PjD\nznGVW+55TD1V3eauHXoRsMJL8RtzQnLyCliz/QApaRkMiK+Lv9+RcxioKt8s38Z9ny8jr6CAJ75Z\nTWRoIG0bRPLI1ytYsHEv/zg7jtv7nsaWvRkcyMpDVUnLyGX9rnTi6kTQp0VMmcQrImV2rpNRpRKs\n/Zl55OQXEB1uY7CM73Tt2pV69eoB0Lx5cwYOHAhAu3btmDFjRonHz5gxg2effZaMjAz27NlDmzZt\nuOCCC45af8GCBfTt25eYGOeGM2zYMGbPns1FF11EUFAQgwcPBqBLly5Mnz79ZC/vVFSawekA/wae\nAe4rqx+uFuQPQEZOPpGhlmAZU1Gpap6I3InTvc8fGK+qK0XkcSBRVacCfYGnRERxuggWLT0jIk1w\nWsBmHXbqj0UkBmdZmyXArRhzCsjKzef1GUm8/esGsnILALh7QAvu6h93SJ3fk1J5c+Z6EjftpXOj\nGrx2dWfun7yMB75cjqpSPTSQl6/oyEWdnAklmseEH/I7Z7Uq//FR5aFKJVipB51xo9aCVXUdT0uT\ntwQH//3fn5+fX9F3Pz8/8vKOPV4nKyuL22+/ncTERBo2bMhjjz1GVlbWCccSGBhYNKOmv79/ib9f\nQZU4OF1EOgMNVfUbESnDBMu5xWbm5Pu0q4Ix5uSp6rfAt4eVPeLxeTJOF+Pijt2Icy86vLxf2UZp\nzPFJy8hhX2YuoYH+1K4eAjhrR10/YQF/pR7kgg71OadNHb5bsZ1Xfl5H77hoVOGl6WuZv3EPOXkF\n1I8M4d9D2nB514YEB/gz9tou/OPTJTSOqsZd/eKIrFb1/v9XtRKsA5ZgmYonIiKCAwcOABQlU9HR\n0aSnpzN58mSGDh16RD1P3bp146677iI1NZWaNWsyceJERo0aVX4XcIoTET+cWb1GlKLucc3kFRbs\ntGDZRBfGGGN8ZemWNNIycw/pOqeqPPL1Sj6ctwmA0EB/fr6nD/VrhPLsD3+y60A2H93Ynd5x0QCc\n2SKGJZvTuP69BezLzKVO9WCG92xMj2ZRnBF36OK+4cEBvDP80OEKVU3VSrDSnQU/bZp2U5GMGDGC\nW2+9tWjyipEjR9K2bVvq1q1L165dj1qvUL169Xj66ac566yziia5GDJkiC8uxVdKGpweAbQFZrqt\neXWBqSJy4eETXRzvTF6hgU6CZVO1G2OMKWup6dms35nOwZw8ujSuVWxPiR37s7hu/Hz2ZeZyWZdY\nHruwDWHBAbz72198OG8TlyfE0rFhTR6bupIXp6/l1j7N+G7Fdm7v27wouQKoHhLIy1d25NYPFzLy\njKaMPrsF4cFVKo04LqJHm86jAkhISNDExNJP9PX+nI08OnUliQ+fba1YVcjq1atp3bp1yRXNURX3\ndygiC1X1lH9FJSIBwFqgP05itQC4WlVXHqX+TODekmYRLM395/ekVIa98wef3dyD7s2iTiR8Y8xh\nKsq9x1uO99nHVE479mdx9ouzOJDl9JCIqx3O5FtPP6Q7nqoWrS91ZddGfDB3I9WCAoivV53ETXs4\np01dXr+6M35+wpPfrOKd3/4ioXFNVqTs5/cH+lErzBokDlfa+0+VSj1T07PxE6hZzf6DMaaqKOXg\ndK/wnOTCGGOMKSvP/7CG7NwCxl3bhay8Au6dtJSbPljABR3qM272BnLzC2hRJ4Jf16Xy6AXxXN+r\nKRd0qM+UxSks2ZJGz+ZRvHB5B/zcWQHvOOs0PluwhQUb9zLyjKaWXJ2kKpdg1QoLKnaKSWNM5VXS\n4PTDyvuW1e8WTnJhCZYxxpiTsT8rlzs+XkTv06I5vXk0kxclc1Pvpgxs4yyk6ycwauJiFmzcS5fG\nNakbGcLvSamcERfN8J5NAOjSuCZdGtcs9vw1qgVx94AWvDh9LSPdNazMiatiCZatgWWMKT+FLVg2\nyYUxxpiT8das9fy6LpVf16US5O9HZGggd57195Tpg9vXJzw4gJBAf7o3rYWIoKpFMwWXxoheTRnW\no7Gt21gGqtTfYGp6tiVYxphyExb89zTtxhhjqo7kvRms3rb/iPK8/AKmLt3KDRMWMODFWfy2LhVw\nxuyOmriYpJ3pAGzafZAxk5exImUfO/Zn8e5vf3FBh/q8dnUn6kQG83/ntT5i+vO+LWvTo1lUUVJ1\nPMlVIUuuykYVa8HKpnGjar4OwxhTRVgLljHGVC3Zefm8NWsDr89IQhXeHZHAGXF/T4/+0k9reX3G\neupFhhAS6M914//gjLgYZq3dBcDMP3dya9/mjJu9gX2ZuXy9NIU29SPJL1DuG9iSRlHVGNy+vq8u\nz5RSlUpTUw9YF0FjTPkJDvDDTyAj21qwjDGmstt5IIuhb87lxelrOTu+Ds1iwrjlw4Us2rwXcBb1\nnfD7Rs5rV5ffx/Rj2qjeDG5fn9nrdnFj76b8fE8fGtaqxnM/rKFeZAhf3n467RvUYOGmvQzr3phG\nUdZIUFFUmRasg9l5ZObmE2UJlqkCpkyZQosWLYiPj/d1KFWaiFAtKMAmuTDGmEpu3Y4DXD9hAbvT\ncxh3bRcGtqnLzgNZXD52LiPGz2fSrT35fsV2Dubkc1f/OPz8hLDgAF65siP/HtK2qLvf5NuceoPa\n1qVaUAAfj+zO9yu20791bR9foTkeVSbB2l24yHC4TTtpKre8vDymTJnC4MGDLcE6BVQL8ifDugga\nY0ylsjUtk3U70/EX4X9LtzJ5UTI1QgP59OYedGhYA4DaESF8eGN3ho6dw7Xvzicnr4CzW9ehVd3q\nRecRkUPGUlULCuCSzrFF3wP9/bigg3UJrGiqTBfBXenZAERHWAuW8Y2PPvqIbt260bFjR2655RY2\nbdpEXFwcqampFBQUcMYZZ/Djjz+yceNGWrVqxbBhw2jdujVDhw4lIyMDgIULF9KnTx+6dOnCOeec\nw7Zt2wDo27cv//jHP0hISOCZZ55h6tSp3HfffXTs2JH169f78rKrvLBga8EyxpiKJHlvBleNm8e/\np61ia1omWbn5rN+VTnaecy9P2nmAc16azfDx87nm3T/4anEK1/ZozHejzyhKrgo1rFWNj27sTm5+\nAfsyc7mz32m+uCRTzqpMC9auA1kAxFgXwSqvb9++ZXq+mTNnllhn9erVfPbZZ/z+++8EBgZy++23\nM2vWLMaMGcNtt91Gt27diI+PZ+DAgWzcuJE1a9bw7rvv0qtXL2644QbeeOMNRo8ezahRo/j666+J\niYnhs88+46GHHmL8+PEA5OTkkJiYCMC6desYPHgwQ4cOLdNrNccvNNBasIypLERkEPAKzqLl76jq\n04ftbwyMB2KAPcA1qprs7ssHlrtVN6vqhW55U+BTIApYCFyrqjnlcDmmGJt2H+Tqt/9gb0YO8zfu\n4b3f/0IBVWgaHca/Brfm//1vFcGB/rx5TRf8/YTmMWHUrh5y1HPG1Yngs5t7sjxlHx0PS8BM5VRl\nEqzpq3YSFuRP0+gwX4diqqCff/6ZhQsX0rVrVwAyMzOpXbs2jz32GJ9//jljx45lyZIlRfUbNmxI\nr169ALjmmmt49dVXGTRoECtWrGDAgAEA5OfnU69evaJjrrjiinK8IlNaYcH+HLRJLoyp8ETEH3gd\nGAAkAwtEZKqqrvKo9jzwgaq+LyL9gKeAa919marasZhTPwO8pKqfishY4EbgTa9diClWenYekxZs\n4Y2Z68kvKGDSLT2pUS2QSQu24OcnRIUHM3bmem6YkEhQgB8TR/Y46qK9xWlZN4KWdSO8eAXmVFIl\nEqx9GblMW7aVS7vEFq1LY6qu0rQ4lTVVZfjw4Tz11FOHlGdkZJCcnAxAeno6ERHOzffwtSsKFwxs\n06YNc+fOLfY3wsLs5cGpKDQogH2Zub4Owxhz8roBSaq6AUBEPgWGAJ4JVjxwt/t5BjDlWCcU52bf\nD7jaLXofeAxLsLwqv0D5KzWdZtHh+PkJM9fs5K6Ji9mflUeXxjX5z8XtipKhuwe2LDru4k4NeH1G\nEl0a1Tyu5MpUPVViDNYXi5LJzivg6m6NfB2KqaL69+/P5MmT2blzJwB79uxh06ZNjBkzhmHDhvH4\n448zcuTIovqbN28uSqQ++eQTevfuTcuWLdm1a1dReW5uLitXriz29yIiIjhw4ICXr8qURliQPxnZ\n1kXQmEqgAbDF43uyW+ZpKXCJ+/liIEJEotzvISKSKCLzROQitywKSFPVwptEcec0J2jbvkzemrWe\ndI97cOLGPVz42m+c/eJsznv1V575/k9ufD+RBjWrMeWOXnxx2+lHbWkKDw5gzKBWnB1fp7wuwVRQ\nlT7BUlU+mb+ZDg1r0LZBpK/DMVVUfHw8TzzxBAMHDqR9+/YMGDCAjRs3smDBgqIkKygoiPfeew+A\nli1b8vrrr9O6dWv27t3LbbfdRlBQEJMnT2bMmDF06NCBjh07MmfOnGJ/78orr+S5556jU6dONsmF\nj9k07cZUKfcCfURkMdAHSAEKbwCNVTUBp7XqZRFpXtqTisjNbnKWuGvXrjIPurJ6/oe1PPXdn5zz\n0mzen7ORa975g6Fj57LnYA73DGhBZm4+b85cz5lx0Xx+a08bH2XKTKXvLzf/rz0k7Uzn2aHtfR2K\nqeKuuOKKI8ZJzZs3r+jzl19+CcDGjRsJCAjgo48+OuIcHTt2ZPbs2UeUH97tsVevXqxateqIeqb8\n2TTtxlQaKUBDj++xblkRVd2K24IlIuHApaqa5u5Lcf/cICIzgU7AF0ANEQlwW7GOOKd7zDhgHEBC\nQoKW7WVVToXDQ85sEUPyngwenbqSepEh3HdOS67v1YRqQQHc2rc5izbtpUvjmgT4V/o2B1OOKn2C\nlZ6dR9sG1bmgva0hYIwpf9WC/a0Fy5jKYQEQ5876lwJcyd9jpwAQkWhgj6oWAA/izCiIiNQEMlQ1\n263TC3hWVVVEZgBDcWYSHA58XV4XVJl9tdgZHnL/OS05rXY4a7YfoE396ockUoH+fnRvFnWMsxhz\nYryWrovIeBHZKSIrPMoeE5EUEVnibud57HtQRJJEZI2InFNWcfRvXYdpo84gNMi/rE5pjFc1adKE\nFStWlFzRVAhhQQFk5xWQl1/g61CMMSfBbWG6E/gBWA1MUtWVIvK4iFzoVusLrBGRtUAd4Em3vDWQ\nKCJLcSa/eNpj9sExwN0ikoQzJuvdcrmgSiYrN58xk5fR74WZLN68l4nzt9A+NpK2DSIJCfSnQ8Ma\n1kplyo03W7AmAK8BHxxW/pKqPu9ZICLxOG+C2gD1gZ9EpIWq2mtfUyZU9YiZ+UzpqFpvlJNRzX25\nk5GbT3X7n7sxFZqqfgt8e1jZIx6fJwOTizluDtDuKOfcgDNDoSml/AIlZW8mOfkFZOXmk5aRywvT\n17B4cxrR4UFc+uYcChSeuqTYv3JjvM5rCZaqzhaRJqWsPgT4VFWzgb/ctzjdgOLnozbmOISEhLB7\n926ioqIsyTpOqsru3bsJCTn6Aorm2KoFObfZzJx8qocE+jgaY4yp2PILlGHvzGPehj2HlIcG+jP2\nms70bBbNfZOXsix5Hxd0sOEhxjd8MQbrThG5DkgE7lHVvThTks7zqHPUaUpF5GbgZoBGjWzadVOy\n2NhYkpOTsZmXTkxISAixsbG+DqPCKmzBOmhTtRtjzEl759cNzNuwh1H9TiOuTgQhAX5UDw2kWUwY\ntSOcl4HjrkugoEDx87OXqsY3yjvBehP4N6Duny8ANxzPCWwmHXO8AgMDadq0qa/DMFVUURdBm+jC\nGGNOytodB3jhx7UMalOXuwfjqY9QAAAgAElEQVS0OGavFEuujC+Va4KlqjsKP4vI28A092uJU58a\nY0xFFBbs3GYtwTLGmOOTkZPHnKTd/LpuFws37+XPbQeIDA3kiYvbWpd/c0or1wRLROqp6jb368VA\n4VRpU4FPRORFnEku4oD55RmbMcZ4Q+EMpgdtLSxjjCm1zbszuGLcXLbtyyI00J/OjWtwS59mDOnY\ngOjwYF+HZ8wxeS3BEpGJONOVRotIMvAo0FdEOuJ0EdwI3ALgTnM6CVgF5AF32AyCxpjKIMxjkgtj\njDElS0nL5Kq355GZm89713fl9OZRBAfYcjum4vDmLIJXFVN81LUdVPVJ/l4vwhhjKgWb5MIYY0pv\nX0Yu17zzBweycvlkZA/aNoj0dUjGHDdfzCJojDFVRmGClZlrLVjGGHMsBQXKPz5bTPLeDEuuTIVm\nq14aY4wXFU5ycTDbEixjjDmWl35ay4w1u3jkgjZ0bVLL1+EYc8KsBcsYY7woOMAPEWc2LGOMMUfK\nySvg8Wkr+WjeZi7rEss13W2dU1OxWYJljDFeJCKEBQXYNO3GGFOM7Lx8rn13PvP/2sMtZzbjvnNa\n2hTspsKzBMsYY7ysWpC/tWAZY0wxXv5pHfP/2sPzl3VgaJdYX4djTJmwMVjGGONlToJlLVjGGONp\n0ea9vDVrPVckNLTkylQqlmAZY4yXVQsKsEkujKngRGSQiKwRkSQReaCY/Y1F5GcRWSYiM0Uk1i3v\nKCJzRWSlu+8Kj2MmiMhfIrLE3TqW5zX5UkpaJvdMWkq9yFAeHtza1+EYU6asi6AxxniZdRE0pmIT\nEX/gdWAAkAwsEJGpqrrKo9rzwAeq+r6I9AOeAq4FMoDrVHWdiNQHForID6qa5h53n6pOLr+r8b0f\nV27nvsnLyC9Q3h2eQERIoK9DMqZMWQuWMabSK8Wb51tFZLn7Bvk3EYkvy9+vUS2I7fuyyvKUxpjy\n1Q1IUtUNqpoDfAoMOaxOPPCL+3lG4X5VXauq69zPW4GdQEy5RH0KWpacxi0fLaRRrWpMG9Wb7s2i\nfB2SMWXOEixjTKXm8eb5XJwHoKuKSaA+UdV2qtoReBZ4sSxjOL15FBtSD7J5d0ZZntYYU34aAFs8\nvie7ZZ6WApe4ny8GIkTkkOxBRLoBQcB6j+In3a6DL4lIcHE/LiI3i0iiiCTu2rXrZK7D5/77SxLV\nQwL5ZGR3mkSH+TocY7zCEixjTGVX4ptnVd3v8TUM0LIMoF+r2gD88ueOsjytMeYEiMiXInK+iJT1\nM9C9QB8RWQz0AVKAosGXIlIP+BC4XlUL3OIHgVZAV6AWMKa4E6vqOFVNUNWEmJiK2/i1ett+pq/a\nwQ29mlq3QFOpWYJljKnsSvPmGRG5Q0TW47Rg3VXciU70LXKT6DCaRYfxy5qK/ebZmEriDeBqYJ2I\nPC0iLUtxTArQ0ON7rFtWRFW3quolqtoJeMgtSwMQkerAN8BDqjrP45ht6sgG3sN5IVRpvT4jifDg\nAEac3sTXoRjjVZZgGWMMoKqvq2pznDfIDx+lzgm/Re7Xqjbz1u/mYLZNdmGML6nqT6o6DOgMbAR+\nEpE5InK9iBytWWUBECciTUUkCLgSmOpZQUSiPVrFHgTGu+VBwFc4E2BMPuyYeu6fAlwErCiLazwV\nbd6dwTfLt3Fdz8ZEVrPWK1O5WYJljKnsSnzzfJhPcR50ylS/VrXJyS/g96TUsj61MeY4uWOjRgA3\nAYuBV3ASrunF1VfVPOBO4AdgNTBJVVeKyOMicqFbrS+wRkTWAnWAJ93yy4EzgRHFTMf+sYgsB5YD\n0cATZXqhp5Bvlm9DFa7u3sjXoRjjdTZNuzGmsit684yTWF2J0z2oiIjEFc7yBZwPrKOMJTSpRURw\nADPW7GRgm7plfXpjTCmJyFdAS5zxUBeo6jZ312cikni041T1W+Dbw8oe8fg8GThiunVV/Qj46Cjn\n7HfcF3CKWrR5Ly//tI43hnUmPPjIx8sfVm6nbYPqxNas5oPojClf1oJljKnUSvnm+U53EdAlwN3A\n8LKOIyjAjzNbxvDjyh3k5heUfIAxxlteVdV4VX3KI7kCQFUTfBVURfflomRmr93FxD82H7Fv+74s\nlmxJ45x4e7lkqgZLsIwxlZ6qfquqLVS1uao+6ZY9oqpT3c+jVbWNqnZU1bNUdaU34ri0cwN2H8zh\nlz93euP0xpjSiReRGoVfRKSmiNzuy4AqmtT0bBZv3sua7QeKyuau3w3AO79tIDsv/5D601c7M6ie\n09YSLFM1lDrBEhF/EakvIo0KN28GZowxlc2ZcTHUjghm0oItJVc2xnjLyMLZ/QBUdS8w0ofxVCiv\n/ryOhCd+4uI35nDBa7+x52AOO/dnsX7XQc5sEcOO/dl8tejQYa4/rtxO0+gw4mqH+yhqY8pXqRIs\nERkF7MAZ/PmNu03zYlzGGFPpBPj7cWmXWGas2cmO/Vm+DseYqsrfnbUPKFqMPMiH8VQYew7m8ObM\n9ZzZIoYnL25LTl4B05ZtZe4Gp/XqngEtaNcgkrGz1pNf4CwnuC8jl7nrdzOwTR08/tqNqdRK24I1\nGmjpdqFp527tvRmYMcZURpd1iaVA4ctFx5rI0BjjRd/jTGjRX0T6AxPdMlOCCXM2kpmbz8Pnt2ZY\n98a0qhvBF4tSmLdhDxHBAbSpX53b+jZn4+4Mpi3bCsBniZvJK1AGt6vv4+iNKT+lTbC2APu8GYgx\nxlQFzWLC6dqkJl8uSvZ1KMZUVWOAGcBt7vYzcL9PI6oA0rPzmPD7XwyMr0OLOhEADO0Sy9ItaXy3\nYhvdmtYiwN+PQW3q0qJOOP/9JYmD2XmMm72B3qdF0y420sdXYEz5KW2CtQGYKSIPisjdhZs3AzPG\nmMqqf+s6rNuZTmp6tq9DMabKUdUCVX1TVYe621uqml/ykVXbJ39sYn9WHrefdVpR2YUd6+MnkJaR\nS8/mUQD4+Qmj+sWRtDOdkR8kkpqew+iz43wVtjE+UdoEazPO+KsgIMJjM8YYc5y6NqkJQOLGvT6O\nxJiqR0TiRGSyiKwSkQ2Fm6/jOpUVFCgfzN1Et6a16NiwaAJGakeEcGaLGAB6NIsqKj+vXT2ax4Qx\nZ/1uejaLomuTWuUeszG+VOJCw+7gzwhVvbcc4jHGmEqvbYNIggL8SNy4h0E2bbEx5e094FHgJeAs\n4Hps2Zpjmr1uF8l7MxkzqNUR+0b1O43o8GBa16teVObvJ9w9oCWjJi7inwNalGeoxpwSSryhuM3m\nvcohFmOMOSYRGS0i1cXxrogsEpGBvo7reAUH+NMhNpLETdaCZYwPhKrqz4Co6iZVfQw438cxndI+\n/mMzUWFBnNPmyBdCXRrX4vnLOuDvd+gMgee3r8eCh86mW1NrvTJVT2nf2CwRkakicq2IXFK4eTUy\nY4w50g2quh8YCNQErgWe9m1IJyahSS1WpOwjM8eGfhhTzrJFxA9YJyJ3isjFgC3QdBTb9mXy8+od\nXN61IUEBx9fQFxUe7KWojDm1lfZfSgiwG+gHXOBug70VlDHGHEXhK9LzgA9VdaVHWYXStUlN8gqU\nJVvSSq5sjClLo4FqwF1AF+AaYLhPIzqFfTh3Ewpc1bWRr0MxpsIocQwWgKpe7+1AjDGmFBaKyI9A\nU+BBEYkACnwc0wnp3MiZ6GLhpj1Fs28ZY7zLHVd+hTuuPB1n/JU5iumrdjB21noGt69Po6hqvg7H\nmAqjVC1YIvKeiIw/fCvhmPEislNEVniU1RKR6SKyzv2zplsuIvKqiCSJyDIR6Xxyl2WMqaRuBB4A\nuqpqBhBIBX1AqlEtiBZ1wllgMwkaU27cceW9T/R4ERkkImvc55UHitnfWER+dp9lZopIrMe+4e7z\nzzoRGe5R3kVElrvnfFVETolW+SVb0hg1cRHtGkTyzKXtfB2OMRVKabsITgO+cbefgeo4b36OZQIw\n6LCyB4CfVTXOPU/hzelcIM7dbgbeLGVcxpiqpSewRlXTROQa4GEq8CLoCU1qsXDTXrLzbByWMeVo\n8YmMK3dbv17HeWaJB64SkfjDqj0PfKCq7YHHgafcY2vhzFzYHegGPFr4khnnmWckfz8HHf7s5BP/\nmrKCqLBg3hnelWpBperwZIxxlSrBUtUvPLaPgcuBhBKOmQ3sOax4CPC++/l94CKP8g/UMQ+oISL1\nSnsRxpgq400gQ0Q6APcA64EPfBvSiRsQX4f07Dxmr031dSjGVCUnOq68G5CkqhtUNQf4FOf5xVM8\n8Iv7eYbH/nOA6aq6R1X34qwtOsh91qmuqvNUVXHuZxfhY5t2H2R5yj5GnN6EmAibqMKY43WiryTi\ngNoncFwdVd3mft4O1HE/NwC2eNRLdsu2cRgRuRmnlYtGjWzApTFVTJ6qqogMAV5T1XdF5EZfB3Wi\nep8WTY1qgXyzbCsD4uuUfIAx5qSdxLjy4p5Vuh9WZylwCfAKcDEQISJRRzm2gbslF1N+iPJ+9vlm\nufP4dW47W6fPmBNRqgRLRA4A6lG0HRhzMj/sPiRpyTWPOG4cMA4gISHhuI83xlRoB0TkQZzp2c9w\np1oO9HFMJyzQ349Bberyv6VbycrNJyTQ39chGVPpich7HPpMA4Cq3lAGp78XeE1ERgCzgRTgpPsA\nl/ezzzfLttGpUQ1ia9rEFsaciNJ2EYxQ1eoeWwtV/eIEfm9HYdc/98+dbnkK0NCjXqxbZowxnq4A\nsnHWw9qOc694zrchnZzz29fjYE4+M9fs8nUoxlQVJzKuHErxrKKqW1X1ElXtBDzklqUd49gU9/NR\nz1neNqYeZOXW/ZzfzkZqGHOiSjuL4M+lKSuFqfy91sRw4GuP8uvc2QR7APs8uhIaYwwAblL1MRAp\nIoOBLFWtsGOwAHo2iyIqLIhpy7b6OhRjqoQTGVfuWgDEiUhTEQkCrsR5fikiItFuyzrAg0DhjMs/\nAANFpKY7ucVA4Af3WWe/iPRwZw+8jr+fjXzi7+6BlmAZc6KOmWCJSIg78020e1Oo5W5NKKaP8GHH\nTgTmAi1FJNkdJ/E0MEBE1gFnu98BvgU2AEnA28DtJ3FNxphKSkQuB+YDl+E8FP0hIkN9G9XJCfD3\n49x2dflx5Q4+/mMTzjh3Y0w5KtW4clXNA+7ESZZWA5NUdaWIPC4iF7rV+gJrRGQtzjjzJ91j9wD/\nxknSFgCPu2XgPPO8g/MMtB74royu67gt3ZLG+N/+okvjmjSoEeqrMIyp8Eoag3UL8A+gPrDIo3w/\n8NqxDlTVq46yq38xdRW4o4RYjDHmIZw1sHYCiEgM8BMw2adRnaR/nt2CTbszeOirFfyelMp/r+qM\nv98psRSOMZXOyYwrV9VvcV4Ke5Y94vF5Mke5H6nqeP5u0fIsTwTalub3vemnVTu4c+IiosODbd0r\nY07SMRMsVX0FeEVERqnqf8spJmOMORq/wuTKtZvSr+d3yooKD+b967vx2owkXpy+ln6tUhjaJbbk\nA40xx01VI3wdw6kmKzefuyctoXlMOBOu72ZTsxtzkkr7YDJeRB4WkXEAIhLnjn8wxpjy9L2I/CAi\nI9xZur7hsLfJFZWfnzCq32l0iI3kxR/XkJVriw8b4w0icrGIRHp8ryEiPl97ypemLdvG/qw8Hj4/\n3pIrY8pAqRMsIAc43f2eAjzhlYiMMeYoVPU+nKmK27vbOFU9qSUjTiUiwgPntmbrviwmzNno63CM\nqaweVdV9hV/cWf4e9WE8PvfJH5toFhNGj2a1fB2KMZVCaROs5qr6LJALoKoZgA0QMMaUO3fmr7vd\n7Stfx1PWejaPol+r2rw+I4mknaWZOdoYc5yKe/Yp1bqgldGf2/ezaHMaV3drhDORoTHmZJU2wcoR\nkVDcQaEi0hxnLRpjjPE6ETkgIvuL2Q6IyH5fx1fWHhkcT3CAP1e8NZfV2yrd5Rnja4ki8qKINHe3\nF4GFvg7KVz75YzNBAX5c2tnGfRpTVkpMsNx1GcYC3wMNReRjnIX57vdybMYYAxS72HnhFqGq1X0d\nX1lrEh3GZ7f0INDfjyvemst/f17H3oM5vg7LmMpiFM6wh8+AT4EsquhMxqrKtGXbOKdNXWqGBfk6\nHGMqjRKbxFVVReQ+nLUdeuB0DRytqqlejs0YY6qs5jHhfH5rTx6esoIXpq/ljZnrefrSdgzpeMwl\nCI0xJVDVg8ADvo7jVLB5TwZ7DuZwevMoX4diTKVS2i6Ci4BmqvqNqk6z5MoYY7yvYa1qvH9DN378\n55m0axDJ6E+X8PR3f1JQYIsRG3OiRGS6iNTw+F5TRH7wZUy+smRLGgAdYmuUUNMYczxKm2B1B+aK\nyHoRWSYiy0VkmTcDM8YY42hRJ4KPburOVd0aMXbWer5dse2Q/arK10tSrBuhMaUT7c4cCICq7gVq\n+zAen1myJY3QQH9a1An3dSjGVCqlTbDOAZoD/YALgMHun8YYY8pBUIAfT17UlgY1QvlswZZD9i1N\n3sfoT5fwzm8bfBSdMRVKgYg0KvwiIk1wJ/GqapZuSaNdg0gC/Cv8eu3GnFJK9S9KVTcVt3k7OGOM\nMX/z8xMuS4jlt6RUtuzJKCr/alEyAL+ts97bxpTCQ8BvIvKhiHwEzAIe9HFM5S4nr4AVW/fToWFk\nyZWNMcfFXlkYYyo9ERkkImtEJElEjhjcLiJ3i8gqtwv0zyLS2BdxlsZlCQ0B+Hyhk1Tl5hfwv2Xb\nCPATlqXsO6KbYHZevo3ZMsaDqn4PJABrgInAPUCmT4PygTXbD5CTV0CHhjb+ypiyZgmWMaZSExF/\n4HXgXCAeuEpE4g+rthhIUNX2wGTg2fKNsvQa1AjljLgYJiduIb9AmbVmF3sO5nBLn2aowpz1uwGY\n8edORn6QSLvHfuTG9xeQlZvv48iNOTWIyE04y83cA9wLfAg8VspjS3pZ00hEZojIYveFzXlu+TAR\nWeKxFYhIR3ffTPechfvKZTzYkmRnGFpHS7CMKXOWYBljKrtuQJKqblDVHJx1b4Z4VlDVGapa2Odu\nHnBKr7h5RUJDtu7L4sEvl/HhvE1EhQUxql8cESEB/Ja0ixUp+7jh/QUsS07jnDZ1mbl2FyM/SLQk\nyxjHaKArsElVzwI6AWnHPqTUL2seBiapaifgSuANAFX9WFU7qmpH4FrgL1Vd4nHcsML9qrrzJK+v\nVJZuSSM6PIgGNULL4+eMqVJKXAfLGGMquAaA56wQyTgzox7NjcB3xe0QkZuBmwEaNWpUXJVyMaht\nXW7s3ZT352wkr0AZcXoTQgL96dksitlrU1m3I51a1YL48Z99iAwN5My4aO7/Yhn3fr6U167u7LO4\njTlFZKlqloggIsGq+qeItCzFcUUvawBEpPBlzSqPOgoULn4eCWwt5jxX4bzo8aklW9LoEFsDEfF1\nKMZUOtaCZYwxLhG5BmdsxnPF7VfVcaqaoKoJMTEx5RucB38/4V+D4/nxn2dyU++m3NKnGQBntIgh\nJS2TxE17uX9QSyJDAwFn3NY9A1owbdk2fly53WdxG3OKSHbXwZoCTBeRr4HSTNxV3Muaw1f+fgy4\nRkSSgW+BUcWc5wqcsV+e3nO7B/5Lisl4RORmEUkUkcRdu3aVItRjy80vYMOudFrXq15yZWPMcbME\nyxhT2aUADT2+x7plhxCRs3FmF7tQVbPLKbaT0iwmnIcHx1Mv0unic8Zp0QC0j43ksi4ND6l7S5/m\ntKobwb++XsH+rNxyj9WYU4WqXqyqaar6GPAv4F3gojI6/VXABFWNBc4DPhSRomctEekOZKjqCo9j\nhqlqO+AMd7u2mJjL9OXO9n1ZFCjE1rTugcZ4gyVYxpjKbgEQJyJNRSQIZ1zEVM8KItIJeAsnuSqX\n8Q/e0DiqGv8aHM9LV3TEz+/Ql+CB/n48O7Q9uw5k88AXy8jJK/BRlMacOlR1lqpOdcdnlqQ0L2tu\nBCa5554LhADRHvuv5LDWK1VNcf88AHyC0xXRq7amOZMmNrAEyxivsATLGFOpqWoecCfwA7AaZwD6\nShF5XEQudKs9B4QDn7vddKYe5XSnNBHhxt5NaR4TXuz+9rE1ePDc1ny7fDvDx89nX4a1ZBlzHEp8\nWQNsBvoDiEhrnARrl/vdD7gcj/FXIhIgItHu50BgMLACL0spTLBsggtjvMImuTDGVHqq+i3OeAjP\nskc8Pp9d7kH5yMgzmxEdEcT9k5cx8OVZjOoXx+UJDQkKsPdtxhyLquaJSOHLGn9gfOHLGiBRVafi\nTP3+toj8E2fCixGqWrgQ3ZnAlsJJMlzBwA9ucuUP/AS87e1rSdnrJFj1LcEyxisswTLGmCrm4k6x\nNIkK48lvVvPwlBX859vVnFY7nNObR3NX/9OoFmT/azCmOKV4WbMK6HWUY2cCPQ4rOwh0KfNAS5CS\nlkl0eBAhgf7l/dPGVAn2ytIYY6qgTo1q8vmtPXn/hm5c0bUh4cEBjJ21nvNe+ZVFm/f6OjxjjBel\npGVa90BjvMgSLGOMqaJEhD4tYnj0gjZ8MrIHE0f2IDdfuWrcPJYll7juqjGmgkpJy7QJLozxIkuw\njDHGANCzeRRT7+xFdHgwIz9IZPu+LF+HZIwpY6rKVmvBMsarLMEyxhhTJCo8mHdHJJCelcfNHyaS\nlZvv65CMMWVo98EcsnILbIILY7zIEixjjDGHaFW3Oi9f2Yllyfv497RVvg7HGFOGCmcQtBYsY7zH\nEixjjDFHGBBfh1v6NOPjPzYzacEWDmbnUVCgHMzOs1YtYyowW2TYGO/zyVy8IrIROADkA3mqmiAi\ntYDPgCbARuByVbWprIwxxkfuG9iSxZvSuP+LZdz/xbKi8vDgAD68sRudGtUEYMueDIID/KgVFkSA\nv723M+ZUVrjIcGyNaj6OxJjKy5eLnZylqqke3x8AflbVp0XkAff7GN+EZowxJsDfj3dGJPDd8m2k\nZeSSmZtPaKA/H8zdxKiJi5k2qjf//SWJd3/7C4CwIH8m3NCNrk1qAXAgK5eIkEBfXoIx5jDJezMJ\nC/Kneqitd2eMt5xK/7qGAH3dz+8DM7EEyxhjfKp6SCBXdG10SFm3prW4bOxczn5xFqnpOVzdvRHx\n9arz+owknvhmNVNuP52lyfu4fOxcruzWkP93YRtExEdXYIzxVDhFu/2bNMZ7fNWXQ4EfRWShiNzs\nltVR1W3u5+1AneIOFJGbRSRRRBJ37dpVHrEaY4zx0KlRTR44txWp6TncP6glT17Ulmt6NOYfZ8ex\ndEsa/1u2jXsmLQHgg7mbeO2XJB9HbIwplLLXpmg3xtt81YLVW1VTRKQ2MF1E/vTcqaoqIlrcgao6\nDhgHkJCQUGwdY4wx3nXTGc24tHMsNcOCisou7RzLW7M3cPdnS8grUN6/oRtfL07hhelrqRUexLDu\njX0YsTEGYOu+TDo3ruHrMIyp1HySYKlqivvnThH5CugG7BCReqq6TUTqATt9EZsxxpjS8UyuwBmz\ndc+AltzxySKu6taIPi1iOL15FHszcnh4ygoiQgJpWDOUcbM30DgqjNvPak51G6NlTLnZti+TtIxc\nmkaH+zoUYyq1ck+wRCQM8FPVA+7ngcDjwFRgOPC0++fX5R2bMcaYk3Neu7pMHNmDTo2cN+SB/n68\nMawLw9+bzz8+XUyBQmRoIN+v3M7khVt46pL2DIgvtke4MaaM/Z60G4CezaJ8HIkxlZsvxmDVAX4T\nkaXAfOAbVf0eJ7EaICLrgLPd78YYYyoQEaFn8yhCAv2LykKD/Hl3eALntq3H6P5x/P5AP6be0Zu6\nkSHc/vFCflvnTCirqqg6Pb93p2dzy4eJ9H9hJs9+/yd/pR70yfUY40lEBonIGhFJcmc8Pnx/IxGZ\nISKLRWSZiJznljcRkUwRWeJuYz2O6SIiy91zvipenH3i96RUosKCaFU3wls/YYzBBy1YqroB6FBM\n+W6gf3nHY4wxxvsiQgJ5fVjnou/tYiP5+KYeXPHWXG75MJFBbesxc81ORIQ+LWL4LWkXezNy6dyo\nBm/N3sD7czYy5Y5exNX5+8EwJS2T1APZtI+NtBnRjNeJiD/wOjAASAYWiMhUVV3lUe1hYJKqviki\n8f+/vTuPzqq+8zj+/iYhCQmQEMJOwhI2AcsWQASpVIpoddTO2IKe2ioj3awOo+3YqcfTOp0ZO7ZO\nbacyVQehjnXFCmOte2ndwLDJTgvIEvZFAQlbku/8cW/wAVlC8iT3Jvm8zrmH597n3l++zy/J9/DN\n/d3fD3iRYH1PgHXuPugUTU8Dbgbmh+dPAP6Q7PjdnbfW7ubCnvmkpOj3RaQuxWmadhERaUJymjdj\n5k3D+bv/foeXV2xnbN92ALy6cjttW2Yw/WvD6N8ph817y7jmwbeZ8thCnppyAf+3dBtPl2xmzY4D\nAFzStx33XD1AM6NJXRsOrA3/UIyZPUmwxExigeVAq/B1DrD1TA2Gz5y3cvd54f5vgKupgwJr7c6P\n2XXgCKOKNDxQpK6pwBIRkci0b5XJq1M/S4oZ6WnBqPXKSseM43elCvKyePD6oVz38DxG3vsGFZXO\n0K6t+cHl51Fe6fzi9b8y/v4/8fOJg/U8l9SlzsDmhP1SYMRJ5/yQYBma7wDZBI88VOluZouB/cBd\n7v5m2GbpSW12PvkLh0vaTAEoLCw8+e1qeWttMBR3VM/8Gl0vItUX1TpYIiIiAGQ2Sz1eXAGkpNin\nhvwN757Hfdd+hnHntePpr49k1jcv5OYxPfjmxUW8MnUMRe1aMOWxBUybu+74c1wne3/zR1zz4Nu8\nsXpHnX4eadImATPcvQtwOfCYmaUA24BCdx8M/CPwWzNrdYZ2TuDuD7l7sbsXt23btkaBvb12D4V5\nWRTkZdXoehGpPt3BEhGRBuGawV24ZnCXTx0vyMviqSkjuePZ9/nJS6tZvOlD7rlqAM8s2MysRaWM\n6N6G8zq25N6XVnP4WCW3/HYxz3xjJAV5WTy/eAvd2mQzWs+lyNltAQoS9ruExxJNJniGCnd/18wy\ngXx33wkcCY8vNLN1QHASeEQAABNhSURBVO/w+sQf6lO1WWvHKiqZv34PVwzslOymReQUVGCJiEiD\n1zw9lf+aNJjBBbnc+4fVvLrqddxhaNfWzHl/K08tqGBwYS7/ds35TJ5Rwlenl3CsopJ9h44B0LVN\nFnd9od/xIYZz1+wkv0UGAzrnRPmxJF5KgF5m1p2gCJoIXHfSOZsIJuyaYWbnAZnALjNrC+x19woz\n6wH0Ata7+14z229mFxBMcnED8MtkB/76qp0cOFLOuPPaJbtpETkFFVgiItIomBl/f1EPirvlMfOd\nDUwcVsCIHm04cPgYy0r3MaRrazKbpfLIV4dx3SPzGFyYy22X9GLT3jKmzV3HlMcW8M+XnccHew7y\n2/mbSE0xbv1cL749toi01BTcnadKNrP/8DEmj+5Bqu54NSnuXm5mtwAvA6nAdHdfYWb3AAvcfQ5w\nO/CwmU0lmPDia+7uZjYGuMfMjgGVwDfcfW/Y9LeAGUBzgsktkj7BxVMlm2jfKoPP9q7Z8EIROTd2\nurHqDUFxcbEvWLAg6jBEmiQzW+juxVHHERXln4atstJPGBJ46GgF//DUYl5eETyfNWVMD3bsP8zs\nJVvp074l3xpbxJ/+sovnFgWjt0b3zOeBiYNo0yIjkvibMuWec8s9Wz86xOifvMG3x/bk9vF96jAy\nkcavuvlHd7BERKTJOfl5q+bpqTx4/VAeffsDitq1YGyfYCjVpf07cP+rf+G2J5cAMHVcbzrkZHD3\n7BVc+cu3mH7jMPp2qPZcBSL17pkFpVQ6fKm44Owni0hSqMASEREBUlOCIYaJLj+/IxP6d+C1VTto\nkZHGheEU1/075TB5ZgnXTnuXX10/hDHh0KuKSmfjnoMcKa8kN6sZHXO0NpdEp7LSeXrBZi7qla/Z\nA0XqkQosERGRM0hJMcb373DCsQGdc/jdt0Zx04wSbpj+HlcN6sSonvn8+k/rWLfrYHCdwX9+eRBX\nDfrUskYi9WL97o/Z8tEhbhvXK+pQRJoUrYMlIiJSA51ymzPrmxdyy9ie/GH5dr737FLSUlL412sG\nMO36IQzrlsfUp5Ywe8kns26v3XmA+19Zw64DR44f21d27IR2Dx+rqLfPII3bht1lAPRs1yLiSESa\nFt3BEhERqaHsjDTuuLQPk0YUsmlPGSO65x1/vuuzfdpy46Ml3PbkEqa/FTzbNXvJVioqnVmLtvCz\nLw1k9pItPPHeZm4Z25M7Lu3DvPV7uPHREm4a3Y3vXto34k8nDd3GvUGB1a1NdsSRiDQtKrBERERq\nqXNuczrnnvi8VVZ6GjNuHM7/ztvI80u28PziLUwaXsiEAR347jNLmfjQPFJTjEEFufzXH9dy4PAx\nZi3aQoU7D85dx6ii/OPPfInUxKY9B2mZkUbrrGZRhyLSpKjAEhERqSPN01O5eUwPbh7Tg/KKStJS\ng5H5s28ZxcN/Xs81QzrTt0Mrbn1iMTPf3UiX1s15bPIIJs8sYerTS/jBF/rx4cGjjOiRp9kK5Zxt\n2FNG1/wszLRmm0h9UoElIo2emU0AHiBYHPQRd7/3pPfHAD8HPgNMdPdn6z9KaeyqiiuA9q0yueuK\nfsf37//yQAYW5HDZgI4U5GXxi4mD+eKD73DrE4uBYIbDGy/sRrtWGfx+6TZ27D9CWqrRv1Mrvv7Z\nIoYUtq73zyPxt2lvGf06qjAXqW8qsESkUTOzVOBXwOeBUqDEzOa4+8qE0zYBXwPuqP8IRSAjLZUp\nY4qO7w/onMOfvzeWjw4dJTs9jQfnruORtz4AYGCXHMb0zudIeSVz1+zi5RU7GNO7LT+8sh892gaT\nGVRUOpv3lrF6+36WbdnHwSMVXDmwI0MKW+tuRhNRXlFJ6YdlTBjQ4ewni0hSqcASkcZuOLDW3dcD\nmNmTwFXA8QLL3TeE71VGEaDIqXTIyaRDTiYA//7F8/n7i7qTlmJ0TZiw4OCRch6fv5FfvrGWCT9/\nkxE98ti+7zAb95ZxtDz4cU5NMdJSjBnvbKBjTiadc5vTtU02t13Si8I2Whupsdq27zDHKpxu+h6L\n1DsVWCLS2HUGNifslwIjIopFpMaK2n56qu3sjDSmjCni6sGd+Y+X1rBi636652cztm87erZrQe/2\nLenboSXllc6Ly7bx1l93s+vAEV5avo3fL9vKxGGFrNy6n1Xb9jNpRCHfuriIkg0f8ue/7OLqwZ0Y\n2jUvgk8qybBxTzCDYGGeZhAUqW8qsEREqsnMpgBTAAoLCyOORuQT7Vpm8tNrB57xnC8VF/Cl4gIA\ntu07xN2zVzDjnQ307dCSC3u24eE31/Pwm+txDxZJ/t/5G5k4rIADh8uZt34vF/XK5/bxvenS+pM7\nIs8tKqV3+5YM6JxTp59Pzt3GvcGC1111B0uk3qnAEpHGbgtQkLDfJTx2ztz9IeAhgOLiYq99aCLR\n6JjTnIe+MpSyoxVkZwT/FVhWuo9Zi0oZWdSGC3q04f5X1jDz3Y3kt0hnaNfWvLhsG79fto07J/Tl\nxlHdeHz+Ju56fjmts5rxf98ZfULh1VhVY8KcQmAmkBuec6e7v2hmnwfuBdKBo8B33f2N8Jq5QEfg\nUNjMeHffWdtYN+4pIz0thQ6tMmvblIicIxVYItLYlQC9zKw7QWE1Ebgu2pBEomdmx4srgPO75HB+\nl0/uRP3oqgFM/XxvWmY2IzXF2PrRIe6evZx7XljJu+v38MbqnVzQI48VW/fz9ccW8uw3LqR5eiqb\n95bx3KItHC6v4KJe+QwpbE1ms9QoPmJSVXPCnLuAp919mpn1A14EugG7gSvdfauZDQBeJhi+XOV6\nd1+QzHg37jlIYV7W8YWvRaT+qMASkUbN3cvN7BaC/9CkAtPdfYWZ3QMscPc5ZjYM+B3QGrjSzH7k\n7v0jDFskFnKz0o+/7pTbnIe+Usx9r6xh2tx19GnfkodvKKZkw14mz1zAkH95lVbN09ix/whmkGrG\ntLnrAMjLTmd0z3zuu/YzZKQ12GLrrBPmAA5UzYueA2wFcPfFCeesAJqbWYa7H6mrYDfuKaNrXuO/\nqygSRyqwRKTRc/cXCf6SnHjs7oTXJQRDB0XkDFJSjH+a0JexfdpR1DablpnN+Fzf9jz8lWLmrd/D\nvkPH6Nomiy8O6UKr5s14Z+1u1mw/wIY9ZcxaVMqR8gruu3YgM9/ewPulHzGoIJeCvCyWle5j5bb9\n/Oam4SesFxYz1Zkw54fAK2b2HSAbGHeKdv4WWHRScfWomVUAs4Afu3uthiC7O5v2lnFhUX5tmhGR\nGlKBJSIiIudkePcTZxcc16894/q1/9R54/t3YHz/YB2m/p1acc8LK5m75jWOlFdSmJfFa6uCR43S\n01I4v3MOew8epV3DfmZoEjDD3X9mZiOBx8xsgLtXAphZf+AnwPiEa6539y1m1pKgwPoK8JvERs91\ngp1dHx+h7GiFJrgQiYgKLBEREalzN43uTnllJW+t3cNtl/RkaNc89h48yvZ9h+nZrgXpabG9c1Wl\nOhPmTAYmALj7u2aWCeQDO82sC8FQ5BvcfV3VBe6+Jfz3gJn9lmAo4gkF1rlOsLOv7Bg98rPp0VZT\ntItEQQWWiIiI1IspY4qYMqbo+H5edjp52elnuCJWqjNhzibgEmCGmZ0HZAK7zCwX+D3BrIJvV51s\nZmlArrvvNrNmwBXAa7UNtFf7lrxxx8W1bUZEaij2fy4SERERiZq7lwNVE+asIpgtcIWZ3WNmfxOe\ndjtws5m9DzwBfC18nuoWoCdwt5ktCbd2QAbwspktBZYQFG4P1+8nE5Fk0x0sERERkWqoxoQ5K4FR\np7jux8CPT9Ps0GTGKCLRi90dLDObYGZrzGytmd0ZdTwiIiIiIiLVFasCK2ERv8uAfsCkcKE+ERER\nERGR2ItVgUXCIn7ufhSoWsRPREREREQk9uL2DNZZF/FLXAsC+NjM1lSj3Xxgd1IirDuKsfbiHh80\nrhi71nUgcbZw4cLdZraxGqc2pu95lBRjcjSGGJV7qpd7oHF8v+NAMSZHY4ixWvknbgXWWSWuBVFd\nZrbA3YvrKKSkUIy1F/f4QDE2Ju7etjrnNYT+VIzJoRiToyHEGKXq5h5oGH2pGJNDMSZHsmKM2xDB\n6iziJyIiIiIiEktxK7COL+JnZukEi/jNiTgmERERERGRaonVEEF3LzezqkX8UoHp7r4iCU2f05DC\niCjG2ot7fKAYm6KG0J+KMTkUY3I0hBgbiobQl4oxORRjciQlRgsWGBcREREREZHaitsQQRERERER\nkQZLBZaIiIiIiEiSNPoCy8wmmNkaM1trZnfGIJ4CM/ujma00sxVmdlt4PM/MXjWzv4b/to5BrKlm\nttjMXgj3u5vZ/LAvnwonIokyvlwze9bMVpvZKjMbGad+NLOp4fd4uZk9YWaZUfehmU03s51mtjzh\n2Cn7zAK/CGNdamZD6jPWhi5uuQeUf+ogxljnoDBG5aEmSPmn1rHGOv8o99QqrnrJP426wDKzVOBX\nwGVAP2CSmfWLNirKgdvdvR9wAfDtMKY7gdfdvRfwergftduAVQn7PwH+0917Ah8CkyOJ6hMPAC+5\ne19gIEGssehHM+sM3AoUu/sAgklbJhJ9H84AJpx07HR9dhnQK9ymANPqKcYGL6a5B5R/ki22OQiU\nh5oq5Z+kiHv+Ue6puRnUR/5x90a7ASOBlxP2vw98P+q4TopxNvB5YA3QMTzWEVgTcVxdwh+yzwEv\nAEawsnXaqfo2gvhygA8IJ2pJOB6LfgQ6A5uBPILZOl8ALo1DHwLdgOVn6zPg18CkU52n7ax9HPvc\nE8al/FPzGGOdg8KvrzzUBDfln1rHFev8o9yTlPjqPP806jtYfPINrlIaHosFM+sGDAbmA+3dfVv4\n1nagfURhVfk58D2gMtxvA3zk7uXhftR92R3YBTwa3sZ/xMyyiUk/uvsW4KfAJmAbsA9YSLz6sMrp\n+izWvz8xF/u+U/6ptVjnIFAeasJi32fKP7Wi3JN8Sc8/jb3Aii0zawHMAv7B3fcnvudBmRzZ/Plm\ndgWw090XRhVDNaQBQ4Bp7j4YOMhJt8Oj7Mdw/O5VBImwE5DNp29Jx07UP3tSP5R/kiLWOQiUhySe\nlH9qTbmnDiWr7xp7gbUFKEjY7xIei5SZNSNILo+7+3Ph4R1m1jF8vyOwM6r4gFHA35jZBuBJgtvk\nDwC5Zla1OHXUfVkKlLr7/HD/WYKEE5d+HAd84O673P0Y8BxBv8apD6ucrs9i+fvTQMS275R/kibu\nOQiUh5qq2PaZ8k9SKPckX9LzT2MvsEqAXuGsJekED9jNiTIgMzPgf4BV7n5/wltzgK+Gr79KMDY5\nEu7+fXfv4u7dCPrsDXe/Hvgj8HfhaVHHuB3YbGZ9wkOXACuJTz9uAi4ws6zwe14VX2z6MMHp+mwO\ncEM4i84FwL6EW+hyZrHLPaD8k0wNIAeB8lBTpfxTQw0h/yj31Ink558oHi6rzw24HPgLsA74QQzi\nGU1w63EpsCTcLicY4/s68FfgNSAv6ljDeC8GXghf9wDeA9YCzwAZEcc2CFgQ9uXzQOs49SPwI2A1\nsBx4DMiIug+BJwjGQx8j+CvY5NP1GcGDvb8Kf3eWEcwGFPnPZEPZ4pZ7wpiUf5IbX6xzUBij8lAT\n3JR/khJvbPOPck+t4qqX/GNhAyIiIiIiIlJLjX2IoIiIiIiISL1RgSUiIiIiIpIkKrBERERERESS\nRAWWiIiIiIhIkqjAEhERERERSRIVWHJGZvZO+G83M7suyW3/86m+logIKP+ISHSUf6Q2NE27VIuZ\nXQzc4e5XnMM1ae5efob3P3b3FsmIT0QaL+UfEYmK8o/UhO5gyRmZ2cfhy3uBi8xsiZlNNbNUM7vP\nzErMbKmZfT08/2Ize9PM5hCs2o2ZPW9mC81shZlNCY/dCzQP23s88WuFK2bfZ2bLzWyZmX05oe25\nZvasma02s8fDFcIxs3vNbGUYy0/rs49EpG4o/4hIVJR/pFaiXOVZW/w34OPw34sJVzQP96cAd4Wv\nMwhWFO8enncQ6J5wbtWK2M0JVvRuk9j2Kb7W3wKvAqlAe2AT0DFsex/QheCPA+8SrAzfBljDJ3dk\nc6PuN23atNV+U/7Rpk1bVJvyj7babLqDJTU1HrjBzJYA8wl+yXuF773n7h8knHurmb0PzAMKEs47\nndHAE+5e4e47gD8BwxLaLnX3SmAJ0I0g6RwG/sfMvgiU1frTiUicKf+ISFSUf+SsVGBJTRnwHXcf\nFG7d3f2V8L2Dx08Kxi6PA0a6+0BgMZBZi697JOF1BVA1znk48CxwBfBSLdoXkfhT/hGRqCj/yFmp\nwJLqOgC0TNh/GfimmTUDMLPeZpZ9iutygA/dvczM+gIXJLx3rOr6k7wJfDkc59wWGAO8d7rAzKwF\nkOPuLwJTgYHn8sFEJPaUf0QkKso/cs7Sog5AGoylQEV4q3sG8ADB7elF4YOWu4CrT3HdS8A3zGwV\nwTjheQnvPQQsNbNF7n59wvHfASOB9wEHvufu28MEdSotgdlmlknwl6V/rNlHFJGYUv4Rkago/8g5\n0zTtIiIiIiIiSaIhgiIiIiIiIkmiAktERERERCRJVGCJiIiIiIgkiQosERERERGRJFGBJSIiIiIi\nkiQqsERERERERJJEBZaIiIiIiEiS/D+3Ajq7mTWtBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Plot the results\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(131)\n",
    "plt.title('Reward')\n",
    "plt.plot(imitation_reward_vec, label='imitation')\n",
    "plt.hlines(expert_reward, 0, len(imitation_reward_vec), label='expert')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('return')\n",
    "plt.legend()\n",
    "plt.ylim([0, None])\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.title('Loss')\n",
    "plt.plot(loss_vec)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(acc_vec)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('accuracy')\n",
    "plt.tight_layout()\n",
    "plt.savefig('student_vs_expert_%s.png' % mode, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4W6BRtNBGyv"
   },
   "source": [
    "### Experiment: How much expert data is needed?\n",
    "This question studies how the amount of expert data effects the performance. You will run the same experiment as above, each time varying the number of expert episodes collected at each iteration. Use values of 1, 10, 50, and 100. You can keep the number of iterations fixed at 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3sE8xQFW3ZbL",
    "outputId": "4d612c78-d3d0-4fa3-ee71-911032de90e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_episodes: 1; seed: 0\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6306 - acc: 0.7750\n",
      "(0) loss = 0.631; accuracy = 0.78; reward = 69.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 67us/step - loss: 0.6251 - acc: 0.8250\n",
      "(0) loss = 0.625; accuracy = 0.82; reward = 66.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.6170 - acc: 0.7900\n",
      "(0) loss = 0.617; accuracy = 0.79; reward = 66.4\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 61us/step - loss: 0.6106 - acc: 0.7550\n",
      "(0) loss = 0.611; accuracy = 0.76; reward = 69.4\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 86us/step - loss: 0.6071 - acc: 0.8150\n",
      "(0) loss = 0.607; accuracy = 0.81; reward = 63.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 69us/step - loss: 0.5975 - acc: 0.7600\n",
      "(0) loss = 0.598; accuracy = 0.76; reward = 64.4\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 91us/step - loss: 0.5911 - acc: 0.8500\n",
      "(0) loss = 0.591; accuracy = 0.85; reward = 62.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 93us/step - loss: 0.5874 - acc: 0.8450\n",
      "(0) loss = 0.587; accuracy = 0.84; reward = 61.9\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 58us/step - loss: 0.5792 - acc: 0.7600\n",
      "(0) loss = 0.579; accuracy = 0.76; reward = 59.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.5732 - acc: 0.7600\n",
      "(0) loss = 0.573; accuracy = 0.76; reward = 58.9\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.5670 - acc: 0.7900\n",
      "(0) loss = 0.567; accuracy = 0.79; reward = 58.0\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.5560 - acc: 0.8850\n",
      "(0) loss = 0.556; accuracy = 0.89; reward = 63.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 70us/step - loss: 0.5557 - acc: 0.7650\n",
      "(0) loss = 0.556; accuracy = 0.77; reward = 65.6\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 88us/step - loss: 0.5474 - acc: 0.8150\n",
      "(0) loss = 0.547; accuracy = 0.81; reward = 64.7\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.5389 - acc: 0.8250\n",
      "(0) loss = 0.539; accuracy = 0.82; reward = 64.8\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.5418 - acc: 0.7750\n",
      "(0) loss = 0.542; accuracy = 0.78; reward = 69.4\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 111us/step - loss: 0.5309 - acc: 0.7800\n",
      "(0) loss = 0.531; accuracy = 0.78; reward = 68.0\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 87us/step - loss: 0.5237 - acc: 0.8200\n",
      "(0) loss = 0.524; accuracy = 0.82; reward = 64.7\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 93us/step - loss: 0.5181 - acc: 0.8300\n",
      "(0) loss = 0.518; accuracy = 0.83; reward = 70.7\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.5144 - acc: 0.7700\n",
      "(0) loss = 0.514; accuracy = 0.77; reward = 71.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 104us/step - loss: 0.5057 - acc: 0.8100\n",
      "(0) loss = 0.506; accuracy = 0.81; reward = 60.0\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 104us/step - loss: 0.5000 - acc: 0.8350\n",
      "(0) loss = 0.500; accuracy = 0.83; reward = 66.0\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 51us/step - loss: 0.4984 - acc: 0.7850\n",
      "(0) loss = 0.498; accuracy = 0.79; reward = 70.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 56us/step - loss: 0.4901 - acc: 0.8050\n",
      "(0) loss = 0.490; accuracy = 0.81; reward = 74.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 89us/step - loss: 0.5219 - acc: 0.6800\n",
      "(0) loss = 0.522; accuracy = 0.68; reward = 68.4\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 94us/step - loss: 0.4809 - acc: 0.8200\n",
      "(0) loss = 0.481; accuracy = 0.82; reward = 64.1\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.4822 - acc: 0.7800\n",
      "(0) loss = 0.482; accuracy = 0.78; reward = 55.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.4809 - acc: 0.8100\n",
      "(0) loss = 0.481; accuracy = 0.81; reward = 59.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 58us/step - loss: 0.4752 - acc: 0.7350\n",
      "(0) loss = 0.475; accuracy = 0.73; reward = 63.6\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.4673 - acc: 0.7950\n",
      "(0) loss = 0.467; accuracy = 0.80; reward = 63.0\n",
      "num_episodes: 1; seed: 1\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.7796 - acc: 0.2700\n",
      "(1) loss = 0.780; accuracy = 0.27; reward = 9.0\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 95us/step - loss: 0.7697 - acc: 0.2600\n",
      "(1) loss = 0.770; accuracy = 0.26; reward = 9.1\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 58us/step - loss: 0.7608 - acc: 0.2500\n",
      "(1) loss = 0.761; accuracy = 0.25; reward = 9.0\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.7517 - acc: 0.2400\n",
      "(1) loss = 0.752; accuracy = 0.24; reward = 9.1\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 81us/step - loss: 0.7438 - acc: 0.1700\n",
      "(1) loss = 0.744; accuracy = 0.17; reward = 9.0\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 65us/step - loss: 0.7356 - acc: 0.1650\n",
      "(1) loss = 0.736; accuracy = 0.17; reward = 9.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 49us/step - loss: 0.7286 - acc: 0.4000\n",
      "(1) loss = 0.729; accuracy = 0.40; reward = 9.0\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 108us/step - loss: 0.7198 - acc: 0.3150\n",
      "(1) loss = 0.720; accuracy = 0.32; reward = 9.4\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.7122 - acc: 0.3400\n",
      "(1) loss = 0.712; accuracy = 0.34; reward = 10.0\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 62us/step - loss: 0.7050 - acc: 0.3550\n",
      "(1) loss = 0.705; accuracy = 0.35; reward = 11.6\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 54us/step - loss: 0.6980 - acc: 0.5000\n",
      "(1) loss = 0.698; accuracy = 0.50; reward = 19.7\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.6898 - acc: 0.6200\n",
      "(1) loss = 0.690; accuracy = 0.62; reward = 41.1\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.6824 - acc: 0.7800\n",
      "(1) loss = 0.682; accuracy = 0.78; reward = 60.4\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 96us/step - loss: 0.6750 - acc: 0.8250\n",
      "(1) loss = 0.675; accuracy = 0.82; reward = 82.8\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 114us/step - loss: 0.6673 - acc: 0.7900\n",
      "(1) loss = 0.667; accuracy = 0.79; reward = 100.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.6599 - acc: 0.7550\n",
      "(1) loss = 0.660; accuracy = 0.76; reward = 130.7\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 91us/step - loss: 0.6522 - acc: 0.8600\n",
      "(1) loss = 0.652; accuracy = 0.86; reward = 144.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 96us/step - loss: 0.6448 - acc: 0.6550\n",
      "(1) loss = 0.645; accuracy = 0.66; reward = 161.9\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 118us/step - loss: 0.6383 - acc: 0.8200\n",
      "(1) loss = 0.638; accuracy = 0.82; reward = 172.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 70us/step - loss: 0.6302 - acc: 0.6800\n",
      "(1) loss = 0.630; accuracy = 0.68; reward = 158.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 66us/step - loss: 0.6233 - acc: 0.7600\n",
      "(1) loss = 0.623; accuracy = 0.76; reward = 135.1\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 64us/step - loss: 0.6157 - acc: 0.7250\n",
      "(1) loss = 0.616; accuracy = 0.72; reward = 118.1\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.6089 - acc: 0.6800\n",
      "(1) loss = 0.609; accuracy = 0.68; reward = 103.0\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 107us/step - loss: 0.6017 - acc: 0.7300\n",
      "(1) loss = 0.602; accuracy = 0.73; reward = 95.6\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.5931 - acc: 0.8000\n",
      "(1) loss = 0.593; accuracy = 0.80; reward = 89.9\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 62us/step - loss: 0.5878 - acc: 0.8100\n",
      "(1) loss = 0.588; accuracy = 0.81; reward = 90.7\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 102us/step - loss: 0.5812 - acc: 0.7150\n",
      "(1) loss = 0.581; accuracy = 0.71; reward = 85.1\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 99us/step - loss: 0.5733 - acc: 0.8250\n",
      "(1) loss = 0.573; accuracy = 0.82; reward = 79.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 68us/step - loss: 0.5671 - acc: 0.8200\n",
      "(1) loss = 0.567; accuracy = 0.82; reward = 83.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.5611 - acc: 0.8250\n",
      "(1) loss = 0.561; accuracy = 0.82; reward = 86.4\n",
      "num_episodes: 1; seed: 2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.7780 - acc: 0.3300\n",
      "(2) loss = 0.778; accuracy = 0.33; reward = 9.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 101us/step - loss: 0.8380 - acc: 0.5000\n",
      "(2) loss = 0.838; accuracy = 0.50; reward = 9.4\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 109us/step - loss: 0.7964 - acc: 0.4400\n",
      "(2) loss = 0.796; accuracy = 0.44; reward = 9.6\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 73us/step - loss: 0.8222 - acc: 0.5000\n",
      "(2) loss = 0.822; accuracy = 0.50; reward = 9.4\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.7479 - acc: 0.3250\n",
      "(2) loss = 0.748; accuracy = 0.33; reward = 9.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.7444 - acc: 0.3600\n",
      "(2) loss = 0.744; accuracy = 0.36; reward = 9.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 91us/step - loss: 0.7360 - acc: 0.2800\n",
      "(2) loss = 0.736; accuracy = 0.28; reward = 9.4\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 70us/step - loss: 0.7732 - acc: 0.4450\n",
      "(2) loss = 0.773; accuracy = 0.45; reward = 9.1\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 59us/step - loss: 0.8077 - acc: 0.4600\n",
      "(2) loss = 0.808; accuracy = 0.46; reward = 9.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 110us/step - loss: 0.7246 - acc: 0.4950\n",
      "(2) loss = 0.725; accuracy = 0.49; reward = 9.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 89us/step - loss: 0.7378 - acc: 0.5050\n",
      "(2) loss = 0.738; accuracy = 0.51; reward = 9.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.7258 - acc: 0.5050\n",
      "(2) loss = 0.726; accuracy = 0.51; reward = 9.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 69us/step - loss: 0.7048 - acc: 0.4500\n",
      "(2) loss = 0.705; accuracy = 0.45; reward = 9.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 87us/step - loss: 0.6971 - acc: 0.4200\n",
      "(2) loss = 0.697; accuracy = 0.42; reward = 9.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 86us/step - loss: 0.6920 - acc: 0.5450\n",
      "(2) loss = 0.692; accuracy = 0.55; reward = 11.9\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 86us/step - loss: 0.6966 - acc: 0.5450\n",
      "(2) loss = 0.697; accuracy = 0.55; reward = 16.6\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.6818 - acc: 0.7100\n",
      "(2) loss = 0.682; accuracy = 0.71; reward = 23.7\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 86us/step - loss: 0.6883 - acc: 0.5300\n",
      "(2) loss = 0.688; accuracy = 0.53; reward = 32.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 89us/step - loss: 0.6715 - acc: 0.6900\n",
      "(2) loss = 0.671; accuracy = 0.69; reward = 35.8\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.6663 - acc: 0.7700\n",
      "(2) loss = 0.666; accuracy = 0.77; reward = 44.1\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.6610 - acc: 0.7250\n",
      "(2) loss = 0.661; accuracy = 0.72; reward = 46.9\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.6586 - acc: 0.6600\n",
      "(2) loss = 0.659; accuracy = 0.66; reward = 51.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.6521 - acc: 0.7000\n",
      "(2) loss = 0.652; accuracy = 0.70; reward = 55.4\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 69us/step - loss: 0.6463 - acc: 0.7450\n",
      "(2) loss = 0.646; accuracy = 0.74; reward = 56.0\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 88us/step - loss: 0.6396 - acc: 0.7600\n",
      "(2) loss = 0.640; accuracy = 0.76; reward = 62.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 96us/step - loss: 0.6346 - acc: 0.7650\n",
      "(2) loss = 0.635; accuracy = 0.77; reward = 57.9\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.6293 - acc: 0.8400\n",
      "(2) loss = 0.629; accuracy = 0.84; reward = 64.8\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.6235 - acc: 0.8000\n",
      "(2) loss = 0.623; accuracy = 0.80; reward = 65.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 120us/step - loss: 0.6257 - acc: 0.6900\n",
      "(2) loss = 0.626; accuracy = 0.69; reward = 66.8\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 67us/step - loss: 0.6222 - acc: 0.6800\n",
      "(2) loss = 0.622; accuracy = 0.68; reward = 64.0\n",
      "num_episodes: 1; seed: 3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6373 - acc: 0.8150\n",
      "(3) loss = 0.637; accuracy = 0.81; reward = 98.1\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 68us/step - loss: 0.6300 - acc: 0.7600\n",
      "(3) loss = 0.630; accuracy = 0.76; reward = 106.9\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.6336 - acc: 0.7000\n",
      "(3) loss = 0.634; accuracy = 0.70; reward = 114.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 92us/step - loss: 0.6131 - acc: 0.7500\n",
      "(3) loss = 0.613; accuracy = 0.75; reward = 126.9\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.6135 - acc: 0.7050\n",
      "(3) loss = 0.614; accuracy = 0.70; reward = 126.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 86us/step - loss: 0.6045 - acc: 0.7400\n",
      "(3) loss = 0.604; accuracy = 0.74; reward = 139.9\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 89us/step - loss: 0.5992 - acc: 0.7200\n",
      "(3) loss = 0.599; accuracy = 0.72; reward = 131.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.5841 - acc: 0.8250\n",
      "(3) loss = 0.584; accuracy = 0.82; reward = 117.6\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.5826 - acc: 0.7700\n",
      "(3) loss = 0.583; accuracy = 0.77; reward = 123.7\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.5705 - acc: 0.8100\n",
      "(3) loss = 0.571; accuracy = 0.81; reward = 114.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 77us/step - loss: 0.5666 - acc: 0.8350\n",
      "(3) loss = 0.567; accuracy = 0.83; reward = 126.6\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.5602 - acc: 0.7900\n",
      "(3) loss = 0.560; accuracy = 0.79; reward = 120.9\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 88us/step - loss: 0.5537 - acc: 0.8350\n",
      "(3) loss = 0.554; accuracy = 0.83; reward = 109.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 66us/step - loss: 0.5486 - acc: 0.7800\n",
      "(3) loss = 0.549; accuracy = 0.78; reward = 116.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.5416 - acc: 0.8500\n",
      "(3) loss = 0.542; accuracy = 0.85; reward = 118.8\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 68us/step - loss: 0.5361 - acc: 0.8400\n",
      "(3) loss = 0.536; accuracy = 0.84; reward = 114.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.5303 - acc: 0.8050\n",
      "(3) loss = 0.530; accuracy = 0.81; reward = 110.7\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.5255 - acc: 0.7950\n",
      "(3) loss = 0.526; accuracy = 0.80; reward = 111.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.5191 - acc: 0.7900\n",
      "(3) loss = 0.519; accuracy = 0.79; reward = 111.7\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 89us/step - loss: 0.5150 - acc: 0.7950\n",
      "(3) loss = 0.515; accuracy = 0.80; reward = 110.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 87us/step - loss: 0.5077 - acc: 0.8300\n",
      "(3) loss = 0.508; accuracy = 0.83; reward = 119.7\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 94us/step - loss: 0.5058 - acc: 0.7700\n",
      "(3) loss = 0.506; accuracy = 0.77; reward = 112.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 87us/step - loss: 0.4997 - acc: 0.7900\n",
      "(3) loss = 0.500; accuracy = 0.79; reward = 114.7\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 64us/step - loss: 0.4957 - acc: 0.7750\n",
      "(3) loss = 0.496; accuracy = 0.78; reward = 114.9\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 89us/step - loss: 0.4859 - acc: 0.8000\n",
      "(3) loss = 0.486; accuracy = 0.80; reward = 128.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.4838 - acc: 0.8200\n",
      "(3) loss = 0.484; accuracy = 0.82; reward = 118.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 57us/step - loss: 0.4812 - acc: 0.7600\n",
      "(3) loss = 0.481; accuracy = 0.76; reward = 120.4\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 80us/step - loss: 0.4660 - acc: 0.9050\n",
      "(3) loss = 0.466; accuracy = 0.91; reward = 120.4\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.4562 - acc: 0.9250\n",
      "(3) loss = 0.456; accuracy = 0.93; reward = 125.6\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 60us/step - loss: 0.4665 - acc: 0.7900\n",
      "(3) loss = 0.467; accuracy = 0.79; reward = 124.4\n",
      "num_episodes: 1; seed: 4\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 0.6873 - acc: 0.5150\n",
      "(4) loss = 0.687; accuracy = 0.52; reward = 30.9\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 89us/step - loss: 0.6786 - acc: 0.7800\n",
      "(4) loss = 0.679; accuracy = 0.78; reward = 37.8\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 83us/step - loss: 0.6753 - acc: 0.5950\n",
      "(4) loss = 0.675; accuracy = 0.59; reward = 49.1\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 66us/step - loss: 0.6708 - acc: 0.5850\n",
      "(4) loss = 0.671; accuracy = 0.58; reward = 56.1\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 63us/step - loss: 0.6576 - acc: 0.7650\n",
      "(4) loss = 0.658; accuracy = 0.77; reward = 55.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 68us/step - loss: 0.6496 - acc: 0.8650\n",
      "(4) loss = 0.650; accuracy = 0.86; reward = 62.6\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 113us/step - loss: 0.6432 - acc: 0.7750\n",
      "(4) loss = 0.643; accuracy = 0.78; reward = 60.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 104us/step - loss: 0.6397 - acc: 0.7150\n",
      "(4) loss = 0.640; accuracy = 0.71; reward = 58.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 93us/step - loss: 0.6295 - acc: 0.8150\n",
      "(4) loss = 0.629; accuracy = 0.81; reward = 58.6\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.6223 - acc: 0.7900\n",
      "(4) loss = 0.622; accuracy = 0.79; reward = 65.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 79us/step - loss: 0.6162 - acc: 0.8300\n",
      "(4) loss = 0.616; accuracy = 0.83; reward = 56.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 71us/step - loss: 0.6090 - acc: 0.7500\n",
      "(4) loss = 0.609; accuracy = 0.75; reward = 60.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 74us/step - loss: 0.6052 - acc: 0.7950\n",
      "(4) loss = 0.605; accuracy = 0.80; reward = 63.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 84us/step - loss: 0.5959 - acc: 0.7700\n",
      "(4) loss = 0.596; accuracy = 0.77; reward = 59.8\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 82us/step - loss: 0.5898 - acc: 0.8350\n",
      "(4) loss = 0.590; accuracy = 0.83; reward = 64.2\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 86us/step - loss: 0.5825 - acc: 0.7500\n",
      "(4) loss = 0.582; accuracy = 0.75; reward = 62.6\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 63us/step - loss: 0.5752 - acc: 0.8750\n",
      "(4) loss = 0.575; accuracy = 0.88; reward = 67.1\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.5690 - acc: 0.8150\n",
      "(4) loss = 0.569; accuracy = 0.81; reward = 67.0\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 105us/step - loss: 0.5613 - acc: 0.8850\n",
      "(4) loss = 0.561; accuracy = 0.89; reward = 66.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 92us/step - loss: 0.5556 - acc: 0.8400\n",
      "(4) loss = 0.556; accuracy = 0.84; reward = 72.9\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 78us/step - loss: 0.5493 - acc: 0.8050\n",
      "(4) loss = 0.549; accuracy = 0.81; reward = 75.7\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 75us/step - loss: 0.5428 - acc: 0.8250\n",
      "(4) loss = 0.543; accuracy = 0.82; reward = 72.6\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 85us/step - loss: 0.5376 - acc: 0.8200\n",
      "(4) loss = 0.538; accuracy = 0.82; reward = 73.3\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 99us/step - loss: 0.5316 - acc: 0.7850\n",
      "(4) loss = 0.532; accuracy = 0.79; reward = 76.5\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 62us/step - loss: 0.5212 - acc: 0.8700\n",
      "(4) loss = 0.521; accuracy = 0.87; reward = 75.8\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 101us/step - loss: 0.5196 - acc: 0.8050\n",
      "(4) loss = 0.520; accuracy = 0.81; reward = 75.8\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.5112 - acc: 0.8150\n",
      "(4) loss = 0.511; accuracy = 0.81; reward = 75.8\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 72us/step - loss: 0.5079 - acc: 0.8050\n",
      "(4) loss = 0.508; accuracy = 0.81; reward = 87.0\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 76us/step - loss: 0.5015 - acc: 0.8350\n",
      "(4) loss = 0.501; accuracy = 0.83; reward = 84.1\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 0s 70us/step - loss: 0.4979 - acc: 0.7700\n",
      "(4) loss = 0.498; accuracy = 0.77; reward = 80.6\n",
      "num_episodes: 10; seed: 0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 1s 560us/step - loss: 0.6061 - acc: 0.7925\n",
      "(0) loss = 0.606; accuracy = 0.79; reward = 73.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.5489 - acc: 0.8080\n",
      "(0) loss = 0.549; accuracy = 0.81; reward = 64.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.5018 - acc: 0.7975\n",
      "(0) loss = 0.502; accuracy = 0.80; reward = 72.4\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.4565 - acc: 0.8115\n",
      "(0) loss = 0.457; accuracy = 0.81; reward = 76.8\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.4160 - acc: 0.8135\n",
      "(0) loss = 0.416; accuracy = 0.81; reward = 84.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.3855 - acc: 0.8205\n",
      "(0) loss = 0.385; accuracy = 0.82; reward = 93.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.3713 - acc: 0.8210\n",
      "(0) loss = 0.371; accuracy = 0.82; reward = 95.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.3523 - acc: 0.8335\n",
      "(0) loss = 0.352; accuracy = 0.83; reward = 109.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.3525 - acc: 0.8090\n",
      "(0) loss = 0.352; accuracy = 0.81; reward = 113.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.3337 - acc: 0.8275\n",
      "(0) loss = 0.334; accuracy = 0.83; reward = 140.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.3357 - acc: 0.8200\n",
      "(0) loss = 0.336; accuracy = 0.82; reward = 135.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 48us/step - loss: 0.3373 - acc: 0.8160\n",
      "(0) loss = 0.337; accuracy = 0.82; reward = 142.9\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 45us/step - loss: 0.3091 - acc: 0.8410\n",
      "(0) loss = 0.309; accuracy = 0.84; reward = 152.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.3190 - acc: 0.8275\n",
      "(0) loss = 0.319; accuracy = 0.83; reward = 146.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.2906 - acc: 0.8500\n",
      "(0) loss = 0.291; accuracy = 0.85; reward = 160.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.3119 - acc: 0.8315\n",
      "(0) loss = 0.312; accuracy = 0.83; reward = 157.5\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.3130 - acc: 0.8220\n",
      "(0) loss = 0.313; accuracy = 0.82; reward = 165.8\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.3135 - acc: 0.8295\n",
      "(0) loss = 0.314; accuracy = 0.83; reward = 155.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.3006 - acc: 0.8425\n",
      "(0) loss = 0.301; accuracy = 0.84; reward = 174.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.2876 - acc: 0.8555\n",
      "(0) loss = 0.288; accuracy = 0.86; reward = 150.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.3068 - acc: 0.8260\n",
      "(0) loss = 0.307; accuracy = 0.83; reward = 163.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.2891 - acc: 0.8505\n",
      "(0) loss = 0.289; accuracy = 0.85; reward = 168.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.2852 - acc: 0.8620\n",
      "(0) loss = 0.285; accuracy = 0.86; reward = 172.9\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.2966 - acc: 0.8325\n",
      "(0) loss = 0.297; accuracy = 0.83; reward = 166.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 47us/step - loss: 0.2829 - acc: 0.8550\n",
      "(0) loss = 0.283; accuracy = 0.85; reward = 185.9\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.3051 - acc: 0.8315\n",
      "(0) loss = 0.305; accuracy = 0.83; reward = 183.7\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.2917 - acc: 0.8425\n",
      "(0) loss = 0.292; accuracy = 0.84; reward = 177.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.3016 - acc: 0.8345\n",
      "(0) loss = 0.302; accuracy = 0.83; reward = 176.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.2774 - acc: 0.8560\n",
      "(0) loss = 0.277; accuracy = 0.86; reward = 181.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.2916 - acc: 0.8435\n",
      "(0) loss = 0.292; accuracy = 0.84; reward = 178.4\n",
      "num_episodes: 10; seed: 1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 1s 529us/step - loss: 0.7452 - acc: 0.2570\n",
      "(1) loss = 0.745; accuracy = 0.26; reward = 9.9\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.6760 - acc: 0.6390\n",
      "(1) loss = 0.676; accuracy = 0.64; reward = 172.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.6132 - acc: 0.8295\n",
      "(1) loss = 0.613; accuracy = 0.83; reward = 101.4\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.5528 - acc: 0.7915\n",
      "(1) loss = 0.553; accuracy = 0.79; reward = 81.8\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.4983 - acc: 0.8215\n",
      "(1) loss = 0.498; accuracy = 0.82; reward = 84.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.4527 - acc: 0.8420\n",
      "(1) loss = 0.453; accuracy = 0.84; reward = 87.9\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.4215 - acc: 0.8150\n",
      "(1) loss = 0.422; accuracy = 0.81; reward = 82.8\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.3915 - acc: 0.8350\n",
      "(1) loss = 0.392; accuracy = 0.83; reward = 94.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.3736 - acc: 0.8255\n",
      "(1) loss = 0.374; accuracy = 0.83; reward = 99.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.3539 - acc: 0.8385\n",
      "(1) loss = 0.354; accuracy = 0.84; reward = 101.4\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.3216 - acc: 0.8680\n",
      "(1) loss = 0.322; accuracy = 0.87; reward = 100.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.3151 - acc: 0.8550\n",
      "(1) loss = 0.315; accuracy = 0.85; reward = 113.5\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.3277 - acc: 0.8380\n",
      "(1) loss = 0.328; accuracy = 0.84; reward = 139.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.3100 - acc: 0.8465\n",
      "(1) loss = 0.310; accuracy = 0.85; reward = 151.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.3044 - acc: 0.8465\n",
      "(1) loss = 0.304; accuracy = 0.85; reward = 143.9\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.2967 - acc: 0.8470\n",
      "(1) loss = 0.297; accuracy = 0.85; reward = 149.5\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.3052 - acc: 0.8480\n",
      "(1) loss = 0.305; accuracy = 0.85; reward = 161.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.3120 - acc: 0.8335\n",
      "(1) loss = 0.312; accuracy = 0.83; reward = 156.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.3120 - acc: 0.8250\n",
      "(1) loss = 0.312; accuracy = 0.82; reward = 172.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.3159 - acc: 0.8150\n",
      "(1) loss = 0.316; accuracy = 0.81; reward = 166.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.3147 - acc: 0.8150\n",
      "(1) loss = 0.315; accuracy = 0.81; reward = 163.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.2974 - acc: 0.8385\n",
      "(1) loss = 0.297; accuracy = 0.84; reward = 173.9\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.2734 - acc: 0.8645\n",
      "(1) loss = 0.273; accuracy = 0.86; reward = 168.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.3017 - acc: 0.8340\n",
      "(1) loss = 0.302; accuracy = 0.83; reward = 172.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.3170 - acc: 0.8145\n",
      "(1) loss = 0.317; accuracy = 0.81; reward = 170.8\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.2765 - acc: 0.8545\n",
      "(1) loss = 0.277; accuracy = 0.85; reward = 184.7\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.2751 - acc: 0.8520\n",
      "(1) loss = 0.275; accuracy = 0.85; reward = 186.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 56us/step - loss: 0.3002 - acc: 0.8380\n",
      "(1) loss = 0.300; accuracy = 0.84; reward = 182.7\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 50us/step - loss: 0.2641 - acc: 0.8690\n",
      "(1) loss = 0.264; accuracy = 0.87; reward = 180.7\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.2672 - acc: 0.8630\n",
      "(1) loss = 0.267; accuracy = 0.86; reward = 187.8\n",
      "num_episodes: 10; seed: 2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 1s 615us/step - loss: 0.7643 - acc: 0.3540\n",
      "(2) loss = 0.764; accuracy = 0.35; reward = 9.4\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 46us/step - loss: 0.6952 - acc: 0.5110\n",
      "(2) loss = 0.695; accuracy = 0.51; reward = 28.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.6437 - acc: 0.7375\n",
      "(2) loss = 0.644; accuracy = 0.74; reward = 63.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.5863 - acc: 0.7895\n",
      "(2) loss = 0.586; accuracy = 0.79; reward = 75.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.5340 - acc: 0.8135\n",
      "(2) loss = 0.534; accuracy = 0.81; reward = 82.7\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.4878 - acc: 0.8370\n",
      "(2) loss = 0.488; accuracy = 0.84; reward = 88.4\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.4501 - acc: 0.8215\n",
      "(2) loss = 0.450; accuracy = 0.82; reward = 90.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.4235 - acc: 0.8105\n",
      "(2) loss = 0.423; accuracy = 0.81; reward = 97.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.3966 - acc: 0.8240\n",
      "(2) loss = 0.397; accuracy = 0.82; reward = 113.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.3768 - acc: 0.8195\n",
      "(2) loss = 0.377; accuracy = 0.82; reward = 100.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.3624 - acc: 0.8215\n",
      "(2) loss = 0.362; accuracy = 0.82; reward = 117.4\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.3503 - acc: 0.8260\n",
      "(2) loss = 0.350; accuracy = 0.83; reward = 114.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.3321 - acc: 0.8515\n",
      "(2) loss = 0.332; accuracy = 0.85; reward = 139.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.3364 - acc: 0.8295\n",
      "(2) loss = 0.336; accuracy = 0.83; reward = 134.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.3295 - acc: 0.8330\n",
      "(2) loss = 0.330; accuracy = 0.83; reward = 140.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.3111 - acc: 0.8430\n",
      "(2) loss = 0.311; accuracy = 0.84; reward = 141.9\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.3296 - acc: 0.8205\n",
      "(2) loss = 0.330; accuracy = 0.82; reward = 160.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.3179 - acc: 0.8320\n",
      "(2) loss = 0.318; accuracy = 0.83; reward = 155.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.3118 - acc: 0.8325\n",
      "(2) loss = 0.312; accuracy = 0.83; reward = 155.4\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.2854 - acc: 0.8625\n",
      "(2) loss = 0.285; accuracy = 0.86; reward = 152.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.3153 - acc: 0.8370\n",
      "(2) loss = 0.315; accuracy = 0.84; reward = 172.5\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.2899 - acc: 0.8540\n",
      "(2) loss = 0.290; accuracy = 0.85; reward = 172.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.2994 - acc: 0.8380\n",
      "(2) loss = 0.299; accuracy = 0.84; reward = 160.9\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.3018 - acc: 0.8315\n",
      "(2) loss = 0.302; accuracy = 0.83; reward = 167.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.2702 - acc: 0.8610\n",
      "(2) loss = 0.270; accuracy = 0.86; reward = 161.7\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.2907 - acc: 0.8365\n",
      "(2) loss = 0.291; accuracy = 0.84; reward = 163.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.2808 - acc: 0.8535\n",
      "(2) loss = 0.281; accuracy = 0.85; reward = 168.9\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.2768 - acc: 0.8500\n",
      "(2) loss = 0.277; accuracy = 0.85; reward = 182.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.2936 - acc: 0.8400\n",
      "(2) loss = 0.294; accuracy = 0.84; reward = 180.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.3008 - acc: 0.8390\n",
      "(2) loss = 0.301; accuracy = 0.84; reward = 179.5\n",
      "num_episodes: 10; seed: 3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 1s 677us/step - loss: 0.6103 - acc: 0.7680\n",
      "(3) loss = 0.610; accuracy = 0.77; reward = 108.4\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.5475 - acc: 0.8025\n",
      "(3) loss = 0.548; accuracy = 0.80; reward = 103.9\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.4950 - acc: 0.8240\n",
      "(3) loss = 0.495; accuracy = 0.82; reward = 127.7\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.4467 - acc: 0.8385\n",
      "(3) loss = 0.447; accuracy = 0.84; reward = 121.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.4057 - acc: 0.8570\n",
      "(3) loss = 0.406; accuracy = 0.86; reward = 113.9\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.3788 - acc: 0.8425\n",
      "(3) loss = 0.379; accuracy = 0.84; reward = 136.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.3461 - acc: 0.8690\n",
      "(3) loss = 0.346; accuracy = 0.87; reward = 135.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.3493 - acc: 0.8290\n",
      "(3) loss = 0.349; accuracy = 0.83; reward = 157.8\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.3348 - acc: 0.8355\n",
      "(3) loss = 0.335; accuracy = 0.84; reward = 159.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.3401 - acc: 0.8195\n",
      "(3) loss = 0.340; accuracy = 0.82; reward = 161.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.3173 - acc: 0.8325\n",
      "(3) loss = 0.317; accuracy = 0.83; reward = 158.9\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.3340 - acc: 0.8210\n",
      "(3) loss = 0.334; accuracy = 0.82; reward = 163.7\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.3041 - acc: 0.8465\n",
      "(3) loss = 0.304; accuracy = 0.85; reward = 157.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.3030 - acc: 0.8515\n",
      "(3) loss = 0.303; accuracy = 0.85; reward = 167.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.3145 - acc: 0.8235\n",
      "(3) loss = 0.315; accuracy = 0.82; reward = 161.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.3023 - acc: 0.8340\n",
      "(3) loss = 0.302; accuracy = 0.83; reward = 168.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.3030 - acc: 0.8455\n",
      "(3) loss = 0.303; accuracy = 0.85; reward = 168.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.3176 - acc: 0.8200\n",
      "(3) loss = 0.318; accuracy = 0.82; reward = 168.5\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.2949 - acc: 0.8440\n",
      "(3) loss = 0.295; accuracy = 0.84; reward = 172.5\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.3093 - acc: 0.8360\n",
      "(3) loss = 0.309; accuracy = 0.84; reward = 182.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.2915 - acc: 0.8405\n",
      "(3) loss = 0.292; accuracy = 0.84; reward = 177.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.2915 - acc: 0.8425\n",
      "(3) loss = 0.292; accuracy = 0.84; reward = 179.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.2857 - acc: 0.8450\n",
      "(3) loss = 0.286; accuracy = 0.84; reward = 185.4\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.3033 - acc: 0.8420\n",
      "(3) loss = 0.303; accuracy = 0.84; reward = 182.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 46us/step - loss: 0.2876 - acc: 0.8565\n",
      "(3) loss = 0.288; accuracy = 0.86; reward = 185.7\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.3092 - acc: 0.8315\n",
      "(3) loss = 0.309; accuracy = 0.83; reward = 182.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.2758 - acc: 0.8560\n",
      "(3) loss = 0.276; accuracy = 0.86; reward = 190.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.2973 - acc: 0.8485\n",
      "(3) loss = 0.297; accuracy = 0.85; reward = 185.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.2892 - acc: 0.8370\n",
      "(3) loss = 0.289; accuracy = 0.84; reward = 196.7\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.2915 - acc: 0.8475\n",
      "(3) loss = 0.292; accuracy = 0.85; reward = 193.9\n",
      "num_episodes: 10; seed: 4\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 1s 592us/step - loss: 0.6593 - acc: 0.7115\n",
      "(4) loss = 0.659; accuracy = 0.71; reward = 58.8\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.5952 - acc: 0.8030\n",
      "(4) loss = 0.595; accuracy = 0.80; reward = 66.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.5353 - acc: 0.8375\n",
      "(4) loss = 0.535; accuracy = 0.84; reward = 83.4\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.4805 - acc: 0.8240\n",
      "(4) loss = 0.480; accuracy = 0.82; reward = 83.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.4369 - acc: 0.8190\n",
      "(4) loss = 0.437; accuracy = 0.82; reward = 85.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.4068 - acc: 0.8085\n",
      "(4) loss = 0.407; accuracy = 0.81; reward = 89.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 45us/step - loss: 0.3794 - acc: 0.8190\n",
      "(4) loss = 0.379; accuracy = 0.82; reward = 119.5\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.3681 - acc: 0.8035\n",
      "(4) loss = 0.368; accuracy = 0.80; reward = 131.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 46us/step - loss: 0.3366 - acc: 0.8455\n",
      "(4) loss = 0.337; accuracy = 0.85; reward = 112.8\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.3392 - acc: 0.8240\n",
      "(4) loss = 0.339; accuracy = 0.82; reward = 147.4\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 48us/step - loss: 0.3274 - acc: 0.8340\n",
      "(4) loss = 0.327; accuracy = 0.83; reward = 133.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.3361 - acc: 0.8245\n",
      "(4) loss = 0.336; accuracy = 0.82; reward = 158.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.3114 - acc: 0.8390\n",
      "(4) loss = 0.311; accuracy = 0.84; reward = 151.8\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.3088 - acc: 0.8380\n",
      "(4) loss = 0.309; accuracy = 0.84; reward = 152.9\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 46us/step - loss: 0.2954 - acc: 0.8515\n",
      "(4) loss = 0.295; accuracy = 0.85; reward = 169.7\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.3137 - acc: 0.8350\n",
      "(4) loss = 0.314; accuracy = 0.83; reward = 161.8\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.3115 - acc: 0.8320\n",
      "(4) loss = 0.312; accuracy = 0.83; reward = 170.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.3196 - acc: 0.8230\n",
      "(4) loss = 0.320; accuracy = 0.82; reward = 168.3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.2697 - acc: 0.8650\n",
      "(4) loss = 0.270; accuracy = 0.86; reward = 162.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.2921 - acc: 0.8390\n",
      "(4) loss = 0.292; accuracy = 0.84; reward = 170.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 45us/step - loss: 0.3033 - acc: 0.8335\n",
      "(4) loss = 0.303; accuracy = 0.83; reward = 175.8\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.2838 - acc: 0.8505\n",
      "(4) loss = 0.284; accuracy = 0.85; reward = 182.5\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.2722 - acc: 0.8580\n",
      "(4) loss = 0.272; accuracy = 0.86; reward = 173.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 45us/step - loss: 0.2665 - acc: 0.8675\n",
      "(4) loss = 0.267; accuracy = 0.87; reward = 193.4\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 47us/step - loss: 0.2845 - acc: 0.8535\n",
      "(4) loss = 0.285; accuracy = 0.85; reward = 184.2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 49us/step - loss: 0.2773 - acc: 0.8675\n",
      "(4) loss = 0.277; accuracy = 0.87; reward = 187.6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 51us/step - loss: 0.2896 - acc: 0.8635\n",
      "(4) loss = 0.290; accuracy = 0.86; reward = 192.7\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.2730 - acc: 0.8530\n",
      "(4) loss = 0.273; accuracy = 0.85; reward = 191.1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.2765 - acc: 0.8385\n",
      "(4) loss = 0.276; accuracy = 0.84; reward = 194.7\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.2661 - acc: 0.8660\n",
      "(4) loss = 0.266; accuracy = 0.87; reward = 198.3\n",
      "num_episodes: 50; seed: 0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 177us/step - loss: 0.5032 - acc: 0.8024\n",
      "(0) loss = 0.503; accuracy = 0.80; reward = 73.9\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 0.3571 - acc: 0.8257\n",
      "(0) loss = 0.357; accuracy = 0.83; reward = 125.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.3247 - acc: 0.8218\n",
      "(0) loss = 0.325; accuracy = 0.82; reward = 151.1\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.3089 - acc: 0.8337\n",
      "(0) loss = 0.309; accuracy = 0.83; reward = 176.4\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2947 - acc: 0.8442\n",
      "(0) loss = 0.295; accuracy = 0.84; reward = 177.9\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2914 - acc: 0.8441\n",
      "(0) loss = 0.291; accuracy = 0.84; reward = 192.4\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.2857 - acc: 0.8520\n",
      "(0) loss = 0.286; accuracy = 0.85; reward = 189.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.2712 - acc: 0.8634\n",
      "(0) loss = 0.271; accuracy = 0.86; reward = 199.2\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.2568 - acc: 0.8663\n",
      "(0) loss = 0.257; accuracy = 0.87; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.2618 - acc: 0.8756\n",
      "(0) loss = 0.262; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.2528 - acc: 0.8757\n",
      "(0) loss = 0.253; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2486 - acc: 0.8789\n",
      "(0) loss = 0.249; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2336 - acc: 0.8941\n",
      "(0) loss = 0.234; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2331 - acc: 0.8966\n",
      "(0) loss = 0.233; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2292 - acc: 0.8903\n",
      "(0) loss = 0.229; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 0.2441 - acc: 0.8774\n",
      "(0) loss = 0.244; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2252 - acc: 0.8917\n",
      "(0) loss = 0.225; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2299 - acc: 0.8904\n",
      "(0) loss = 0.230; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.2239 - acc: 0.8985\n",
      "(0) loss = 0.224; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2249 - acc: 0.9099\n",
      "(0) loss = 0.225; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.2338 - acc: 0.8995\n",
      "(0) loss = 0.234; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2180 - acc: 0.8955\n",
      "(0) loss = 0.218; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2278 - acc: 0.8929\n",
      "(0) loss = 0.228; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2072 - acc: 0.9037\n",
      "(0) loss = 0.207; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2083 - acc: 0.9100\n",
      "(0) loss = 0.208; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.2143 - acc: 0.9060\n",
      "(0) loss = 0.214; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.2112 - acc: 0.9088\n",
      "(0) loss = 0.211; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2061 - acc: 0.9082\n",
      "(0) loss = 0.206; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.1957 - acc: 0.9136\n",
      "(0) loss = 0.196; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.2039 - acc: 0.9150\n",
      "(0) loss = 0.204; accuracy = 0.92; reward = 200.0\n",
      "num_episodes: 50; seed: 1\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 148us/step - loss: 0.6153 - acc: 0.6803\n",
      "(1) loss = 0.615; accuracy = 0.68; reward = 86.1\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 0.3989 - acc: 0.8203\n",
      "(1) loss = 0.399; accuracy = 0.82; reward = 107.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.3275 - acc: 0.8375\n",
      "(1) loss = 0.327; accuracy = 0.84; reward = 148.3\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.3006 - acc: 0.8474\n",
      "(1) loss = 0.301; accuracy = 0.85; reward = 155.4\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2935 - acc: 0.8458\n",
      "(1) loss = 0.293; accuracy = 0.85; reward = 179.7\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2824 - acc: 0.8476\n",
      "(1) loss = 0.282; accuracy = 0.85; reward = 184.8\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2791 - acc: 0.8535\n",
      "(1) loss = 0.279; accuracy = 0.85; reward = 193.6\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2817 - acc: 0.8514\n",
      "(1) loss = 0.282; accuracy = 0.85; reward = 197.7\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2649 - acc: 0.8690\n",
      "(1) loss = 0.265; accuracy = 0.87; reward = 199.8\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2710 - acc: 0.8630\n",
      "(1) loss = 0.271; accuracy = 0.86; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.2595 - acc: 0.8706\n",
      "(1) loss = 0.260; accuracy = 0.87; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2567 - acc: 0.8747\n",
      "(1) loss = 0.257; accuracy = 0.87; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2439 - acc: 0.8818\n",
      "(1) loss = 0.244; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.2379 - acc: 0.8885\n",
      "(1) loss = 0.238; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2233 - acc: 0.8984\n",
      "(1) loss = 0.223; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.2212 - acc: 0.8956\n",
      "(1) loss = 0.221; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2210 - acc: 0.9001\n",
      "(1) loss = 0.221; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.2225 - acc: 0.8954\n",
      "(1) loss = 0.223; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.2153 - acc: 0.9003\n",
      "(1) loss = 0.215; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.2172 - acc: 0.8970\n",
      "(1) loss = 0.217; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2143 - acc: 0.9075\n",
      "(1) loss = 0.214; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2226 - acc: 0.8995\n",
      "(1) loss = 0.223; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2110 - acc: 0.9098\n",
      "(1) loss = 0.211; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 0.2095 - acc: 0.9087\n",
      "(1) loss = 0.209; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.2026 - acc: 0.9154\n",
      "(1) loss = 0.203; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 36us/step - loss: 0.2062 - acc: 0.9065\n",
      "(1) loss = 0.206; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.2084 - acc: 0.9131\n",
      "(1) loss = 0.208; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2048 - acc: 0.9137\n",
      "(1) loss = 0.205; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.1939 - acc: 0.9228\n",
      "(1) loss = 0.194; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.1880 - acc: 0.9244\n",
      "(1) loss = 0.188; accuracy = 0.92; reward = 200.0\n",
      "num_episodes: 50; seed: 2\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 187us/step - loss: 0.6467 - acc: 0.6410\n",
      "(2) loss = 0.647; accuracy = 0.64; reward = 81.7\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.4283 - acc: 0.8238\n",
      "(2) loss = 0.428; accuracy = 0.82; reward = 98.3\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.3456 - acc: 0.8253\n",
      "(2) loss = 0.346; accuracy = 0.83; reward = 135.9\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.3204 - acc: 0.8289\n",
      "(2) loss = 0.320; accuracy = 0.83; reward = 161.2\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.3058 - acc: 0.8342\n",
      "(2) loss = 0.306; accuracy = 0.83; reward = 176.7\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 0.2965 - acc: 0.8416\n",
      "(2) loss = 0.297; accuracy = 0.84; reward = 179.8\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.2825 - acc: 0.8564\n",
      "(2) loss = 0.282; accuracy = 0.86; reward = 188.9\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2720 - acc: 0.8619\n",
      "(2) loss = 0.272; accuracy = 0.86; reward = 196.1\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2681 - acc: 0.8619\n",
      "(2) loss = 0.268; accuracy = 0.86; reward = 199.7\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.2562 - acc: 0.8757\n",
      "(2) loss = 0.256; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2476 - acc: 0.8800\n",
      "(2) loss = 0.248; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 0.2488 - acc: 0.8892\n",
      "(2) loss = 0.249; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2455 - acc: 0.8824\n",
      "(2) loss = 0.246; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.2405 - acc: 0.8846\n",
      "(2) loss = 0.241; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2171 - acc: 0.9016\n",
      "(2) loss = 0.217; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.2251 - acc: 0.8974\n",
      "(2) loss = 0.225; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2194 - acc: 0.9003\n",
      "(2) loss = 0.219; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.2198 - acc: 0.9018\n",
      "(2) loss = 0.220; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2233 - acc: 0.9019\n",
      "(2) loss = 0.223; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2085 - acc: 0.9091\n",
      "(2) loss = 0.209; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2172 - acc: 0.9100\n",
      "(2) loss = 0.217; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2318 - acc: 0.9001\n",
      "(2) loss = 0.232; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2254 - acc: 0.8915\n",
      "(2) loss = 0.225; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 37us/step - loss: 0.2070 - acc: 0.9124\n",
      "(2) loss = 0.207; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 47us/step - loss: 0.2152 - acc: 0.9135\n",
      "(2) loss = 0.215; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2100 - acc: 0.9013\n",
      "(2) loss = 0.210; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.1988 - acc: 0.9163\n",
      "(2) loss = 0.199; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2069 - acc: 0.9099\n",
      "(2) loss = 0.207; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2061 - acc: 0.9149\n",
      "(2) loss = 0.206; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2030 - acc: 0.9140\n",
      "(2) loss = 0.203; accuracy = 0.91; reward = 200.0\n",
      "num_episodes: 50; seed: 3\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 229us/step - loss: 0.5056 - acc: 0.8118\n",
      "(3) loss = 0.506; accuracy = 0.81; reward = 131.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.3465 - acc: 0.8484\n",
      "(3) loss = 0.346; accuracy = 0.85; reward = 169.7\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.3053 - acc: 0.8456\n",
      "(3) loss = 0.305; accuracy = 0.85; reward = 165.3\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2924 - acc: 0.8490\n",
      "(3) loss = 0.292; accuracy = 0.85; reward = 179.3\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.2931 - acc: 0.8416\n",
      "(3) loss = 0.293; accuracy = 0.84; reward = 187.9\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2924 - acc: 0.8471\n",
      "(3) loss = 0.292; accuracy = 0.85; reward = 196.2\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.2726 - acc: 0.8576\n",
      "(3) loss = 0.273; accuracy = 0.86; reward = 198.4\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2634 - acc: 0.8638\n",
      "(3) loss = 0.263; accuracy = 0.86; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.2653 - acc: 0.8717\n",
      "(3) loss = 0.265; accuracy = 0.87; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2492 - acc: 0.8817\n",
      "(3) loss = 0.249; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.2419 - acc: 0.8838\n",
      "(3) loss = 0.242; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2424 - acc: 0.8841\n",
      "(3) loss = 0.242; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2252 - acc: 0.8943\n",
      "(3) loss = 0.225; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.2380 - acc: 0.8937\n",
      "(3) loss = 0.238; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 48us/step - loss: 0.2332 - acc: 0.8890\n",
      "(3) loss = 0.233; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2185 - acc: 0.9050\n",
      "(3) loss = 0.218; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.2142 - acc: 0.9082\n",
      "(3) loss = 0.214; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.2207 - acc: 0.9117\n",
      "(3) loss = 0.221; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.2227 - acc: 0.9075\n",
      "(3) loss = 0.223; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.2155 - acc: 0.9060\n",
      "(3) loss = 0.216; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2169 - acc: 0.9102\n",
      "(3) loss = 0.217; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.2034 - acc: 0.9145\n",
      "(3) loss = 0.203; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.1953 - acc: 0.9201\n",
      "(3) loss = 0.195; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2042 - acc: 0.9264\n",
      "(3) loss = 0.204; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.2018 - acc: 0.9178\n",
      "(3) loss = 0.202; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.1948 - acc: 0.9208\n",
      "(3) loss = 0.195; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.1948 - acc: 0.9241\n",
      "(3) loss = 0.195; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.1986 - acc: 0.9201\n",
      "(3) loss = 0.199; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 39us/step - loss: 0.1823 - acc: 0.9272\n",
      "(3) loss = 0.182; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.1829 - acc: 0.9337\n",
      "(3) loss = 0.183; accuracy = 0.93; reward = 200.0\n",
      "num_episodes: 50; seed: 4\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 2s 239us/step - loss: 0.5423 - acc: 0.7958\n",
      "(4) loss = 0.542; accuracy = 0.80; reward = 94.3\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.3690 - acc: 0.8195\n",
      "(4) loss = 0.369; accuracy = 0.82; reward = 140.9\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.3190 - acc: 0.8321\n",
      "(4) loss = 0.319; accuracy = 0.83; reward = 161.4\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 51us/step - loss: 0.2893 - acc: 0.8528\n",
      "(4) loss = 0.289; accuracy = 0.85; reward = 178.7\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.2970 - acc: 0.8394\n",
      "(4) loss = 0.297; accuracy = 0.84; reward = 182.4\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.2833 - acc: 0.8504\n",
      "(4) loss = 0.283; accuracy = 0.85; reward = 195.8\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 42us/step - loss: 0.2624 - acc: 0.8703\n",
      "(4) loss = 0.262; accuracy = 0.87; reward = 198.7\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.2533 - acc: 0.8780\n",
      "(4) loss = 0.253; accuracy = 0.88; reward = 199.5\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.2474 - acc: 0.8742\n",
      "(4) loss = 0.247; accuracy = 0.87; reward = 199.8\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 38us/step - loss: 0.2496 - acc: 0.8790\n",
      "(4) loss = 0.250; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.2657 - acc: 0.8757\n",
      "(4) loss = 0.266; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.2382 - acc: 0.8907\n",
      "(4) loss = 0.238; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.2256 - acc: 0.8992\n",
      "(4) loss = 0.226; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.2189 - acc: 0.8905\n",
      "(4) loss = 0.219; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2383 - acc: 0.8886\n",
      "(4) loss = 0.238; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2270 - acc: 0.9013\n",
      "(4) loss = 0.227; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.2191 - acc: 0.9044\n",
      "(4) loss = 0.219; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.2370 - acc: 0.8965\n",
      "(4) loss = 0.237; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 41us/step - loss: 0.2101 - acc: 0.9032\n",
      "(4) loss = 0.210; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.2169 - acc: 0.9042\n",
      "(4) loss = 0.217; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 44us/step - loss: 0.2164 - acc: 0.9056\n",
      "(4) loss = 0.216; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2052 - acc: 0.9136\n",
      "(4) loss = 0.205; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 43us/step - loss: 0.2034 - acc: 0.9154\n",
      "(4) loss = 0.203; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2010 - acc: 0.9112\n",
      "(4) loss = 0.201; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2021 - acc: 0.9091\n",
      "(4) loss = 0.202; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 40us/step - loss: 0.2000 - acc: 0.9168\n",
      "(4) loss = 0.200; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 45us/step - loss: 0.2082 - acc: 0.9159\n",
      "(4) loss = 0.208; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 1s 52us/step - loss: 0.1929 - acc: 0.9221\n",
      "(4) loss = 0.193; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.1986 - acc: 0.9163\n",
      "(4) loss = 0.199; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 0s 46us/step - loss: 0.2001 - acc: 0.9225\n",
      "(4) loss = 0.200; accuracy = 0.92; reward = 200.0\n",
      "num_episodes: 100; seed: 0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 3s 138us/step - loss: 0.4303 - acc: 0.8155\n",
      "(0) loss = 0.430; accuracy = 0.82; reward = 116.2\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.3167 - acc: 0.8278\n",
      "(0) loss = 0.317; accuracy = 0.83; reward = 169.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.2979 - acc: 0.8395\n",
      "(0) loss = 0.298; accuracy = 0.84; reward = 185.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 48us/step - loss: 0.2785 - acc: 0.8543\n",
      "(0) loss = 0.279; accuracy = 0.85; reward = 199.9\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.2685 - acc: 0.8648\n",
      "(0) loss = 0.268; accuracy = 0.86; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 50us/step - loss: 0.2481 - acc: 0.8773\n",
      "(0) loss = 0.248; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 46us/step - loss: 0.2387 - acc: 0.8935\n",
      "(0) loss = 0.239; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.2294 - acc: 0.8904\n",
      "(0) loss = 0.229; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.2174 - acc: 0.9036\n",
      "(0) loss = 0.217; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.2207 - acc: 0.8962\n",
      "(0) loss = 0.221; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.2284 - acc: 0.8972\n",
      "(0) loss = 0.228; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.2184 - acc: 0.9010\n",
      "(0) loss = 0.218; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.2129 - acc: 0.9066\n",
      "(0) loss = 0.213; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 49us/step - loss: 0.2158 - acc: 0.9084\n",
      "(0) loss = 0.216; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 49us/step - loss: 0.2069 - acc: 0.9100\n",
      "(0) loss = 0.207; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 52us/step - loss: 0.1982 - acc: 0.9163\n",
      "(0) loss = 0.198; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.1945 - acc: 0.9170\n",
      "(0) loss = 0.195; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.1979 - acc: 0.9213\n",
      "(0) loss = 0.198; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 40us/step - loss: 0.1893 - acc: 0.9262\n",
      "(0) loss = 0.189; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 49us/step - loss: 0.1837 - acc: 0.9304\n",
      "(0) loss = 0.184; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 50us/step - loss: 0.1833 - acc: 0.9345\n",
      "(0) loss = 0.183; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.1845 - acc: 0.9283\n",
      "(0) loss = 0.184; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 52us/step - loss: 0.1828 - acc: 0.9336\n",
      "(0) loss = 0.183; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 48us/step - loss: 0.1774 - acc: 0.9349\n",
      "(0) loss = 0.177; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 56us/step - loss: 0.1728 - acc: 0.9379\n",
      "(0) loss = 0.173; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.1712 - acc: 0.9390\n",
      "(0) loss = 0.171; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.1689 - acc: 0.9435\n",
      "(0) loss = 0.169; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.1687 - acc: 0.9438\n",
      "(0) loss = 0.169; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.1605 - acc: 0.9435\n",
      "(0) loss = 0.160; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.1625 - acc: 0.9435\n",
      "(0) loss = 0.162; accuracy = 0.94; reward = 200.0\n",
      "num_episodes: 100; seed: 1\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 3s 144us/step - loss: 0.5059 - acc: 0.7490\n",
      "(1) loss = 0.506; accuracy = 0.75; reward = 108.5\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.3201 - acc: 0.8338\n",
      "(1) loss = 0.320; accuracy = 0.83; reward = 165.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 51us/step - loss: 0.2877 - acc: 0.8495\n",
      "(1) loss = 0.288; accuracy = 0.85; reward = 190.8\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 49us/step - loss: 0.2739 - acc: 0.8572\n",
      "(1) loss = 0.274; accuracy = 0.86; reward = 199.4\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 48us/step - loss: 0.2587 - acc: 0.8713\n",
      "(1) loss = 0.259; accuracy = 0.87; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.2554 - acc: 0.8754\n",
      "(1) loss = 0.255; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 53us/step - loss: 0.2487 - acc: 0.8853\n",
      "(1) loss = 0.249; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 48us/step - loss: 0.2353 - acc: 0.8934\n",
      "(1) loss = 0.235; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.2284 - acc: 0.8932\n",
      "(1) loss = 0.228; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.2155 - acc: 0.9040\n",
      "(1) loss = 0.215; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.2128 - acc: 0.9050\n",
      "(1) loss = 0.213; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.2087 - acc: 0.9053\n",
      "(1) loss = 0.209; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 46us/step - loss: 0.2010 - acc: 0.9107\n",
      "(1) loss = 0.201; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.1976 - acc: 0.9154\n",
      "(1) loss = 0.198; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.2006 - acc: 0.9181\n",
      "(1) loss = 0.201; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.1917 - acc: 0.9242\n",
      "(1) loss = 0.192; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.1850 - acc: 0.9285\n",
      "(1) loss = 0.185; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.1899 - acc: 0.9303\n",
      "(1) loss = 0.190; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.1849 - acc: 0.9303\n",
      "(1) loss = 0.185; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.1791 - acc: 0.9324\n",
      "(1) loss = 0.179; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.1765 - acc: 0.9363\n",
      "(1) loss = 0.177; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 41us/step - loss: 0.1744 - acc: 0.9389\n",
      "(1) loss = 0.174; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.1739 - acc: 0.9376\n",
      "(1) loss = 0.174; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.1679 - acc: 0.9379\n",
      "(1) loss = 0.168; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.1666 - acc: 0.9435\n",
      "(1) loss = 0.167; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.1727 - acc: 0.9411\n",
      "(1) loss = 0.173; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.1591 - acc: 0.9443\n",
      "(1) loss = 0.159; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 50us/step - loss: 0.1621 - acc: 0.9458\n",
      "(1) loss = 0.162; accuracy = 0.95; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.1587 - acc: 0.9452\n",
      "(1) loss = 0.159; accuracy = 0.95; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 50us/step - loss: 0.1563 - acc: 0.9498\n",
      "(1) loss = 0.156; accuracy = 0.95; reward = 200.0\n",
      "num_episodes: 100; seed: 2\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 3s 141us/step - loss: 0.5358 - acc: 0.7300\n",
      "(2) loss = 0.536; accuracy = 0.73; reward = 112.7\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.3266 - acc: 0.8339\n",
      "(2) loss = 0.327; accuracy = 0.83; reward = 154.1\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.3018 - acc: 0.8383\n",
      "(2) loss = 0.302; accuracy = 0.84; reward = 179.2\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.2794 - acc: 0.8535\n",
      "(2) loss = 0.279; accuracy = 0.85; reward = 199.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.2608 - acc: 0.8737\n",
      "(2) loss = 0.261; accuracy = 0.87; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 51us/step - loss: 0.2492 - acc: 0.8818\n",
      "(2) loss = 0.249; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.2420 - acc: 0.8833\n",
      "(2) loss = 0.242; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.2297 - acc: 0.8972\n",
      "(2) loss = 0.230; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.2299 - acc: 0.8967\n",
      "(2) loss = 0.230; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.2034 - acc: 0.9100\n",
      "(2) loss = 0.203; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.2113 - acc: 0.9062\n",
      "(2) loss = 0.211; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 50us/step - loss: 0.2036 - acc: 0.9148\n",
      "(2) loss = 0.204; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 52us/step - loss: 0.2114 - acc: 0.9128\n",
      "(2) loss = 0.211; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.2116 - acc: 0.9085\n",
      "(2) loss = 0.212; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.2115 - acc: 0.9099\n",
      "(2) loss = 0.212; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 53us/step - loss: 0.1972 - acc: 0.9186\n",
      "(2) loss = 0.197; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.2048 - acc: 0.9199\n",
      "(2) loss = 0.205; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 49us/step - loss: 0.1948 - acc: 0.9209\n",
      "(2) loss = 0.195; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.2042 - acc: 0.9148\n",
      "(2) loss = 0.204; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 48us/step - loss: 0.1918 - acc: 0.9215\n",
      "(2) loss = 0.192; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 48us/step - loss: 0.1874 - acc: 0.9262\n",
      "(2) loss = 0.187; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.1792 - acc: 0.9288\n",
      "(2) loss = 0.179; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.1798 - acc: 0.9319\n",
      "(2) loss = 0.180; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.1759 - acc: 0.9369\n",
      "(2) loss = 0.176; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.1762 - acc: 0.9391\n",
      "(2) loss = 0.176; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.1753 - acc: 0.9392\n",
      "(2) loss = 0.175; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.1674 - acc: 0.9415\n",
      "(2) loss = 0.167; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.1693 - acc: 0.9397\n",
      "(2) loss = 0.169; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.1717 - acc: 0.9403\n",
      "(2) loss = 0.172; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 40us/step - loss: 0.1632 - acc: 0.9435\n",
      "(2) loss = 0.163; accuracy = 0.94; reward = 200.0\n",
      "num_episodes: 100; seed: 3\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 3s 152us/step - loss: 0.4290 - acc: 0.8239\n",
      "(3) loss = 0.429; accuracy = 0.82; reward = 147.1\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.2996 - acc: 0.8457\n",
      "(3) loss = 0.300; accuracy = 0.85; reward = 176.6\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.2746 - acc: 0.8591\n",
      "(3) loss = 0.275; accuracy = 0.86; reward = 196.8\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.2764 - acc: 0.8617\n",
      "(3) loss = 0.276; accuracy = 0.86; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 46us/step - loss: 0.2544 - acc: 0.8776\n",
      "(3) loss = 0.254; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.2448 - acc: 0.8886\n",
      "(3) loss = 0.245; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.2298 - acc: 0.8999\n",
      "(3) loss = 0.230; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.2219 - acc: 0.8993\n",
      "(3) loss = 0.222; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.2159 - acc: 0.9052\n",
      "(3) loss = 0.216; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.2189 - acc: 0.9017\n",
      "(3) loss = 0.219; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.2069 - acc: 0.9157\n",
      "(3) loss = 0.207; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 42us/step - loss: 0.2061 - acc: 0.9178\n",
      "(3) loss = 0.206; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.1978 - acc: 0.9237\n",
      "(3) loss = 0.198; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.1982 - acc: 0.9208\n",
      "(3) loss = 0.198; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.1923 - acc: 0.9231\n",
      "(3) loss = 0.192; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 46us/step - loss: 0.1905 - acc: 0.9299\n",
      "(3) loss = 0.191; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 48us/step - loss: 0.1822 - acc: 0.9335\n",
      "(3) loss = 0.182; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 48us/step - loss: 0.1768 - acc: 0.9366\n",
      "(3) loss = 0.177; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.1829 - acc: 0.9334\n",
      "(3) loss = 0.183; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 48us/step - loss: 0.1755 - acc: 0.9399\n",
      "(3) loss = 0.176; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.1732 - acc: 0.9371\n",
      "(3) loss = 0.173; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.1776 - acc: 0.9375\n",
      "(3) loss = 0.178; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.1692 - acc: 0.9438\n",
      "(3) loss = 0.169; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 46us/step - loss: 0.1730 - acc: 0.9390\n",
      "(3) loss = 0.173; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.1693 - acc: 0.9428\n",
      "(3) loss = 0.169; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 48us/step - loss: 0.1659 - acc: 0.9436\n",
      "(3) loss = 0.166; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.1670 - acc: 0.9453\n",
      "(3) loss = 0.167; accuracy = 0.95; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 47us/step - loss: 0.1619 - acc: 0.9448\n",
      "(3) loss = 0.162; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.1541 - acc: 0.9515\n",
      "(3) loss = 0.154; accuracy = 0.95; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.1621 - acc: 0.9431\n",
      "(3) loss = 0.162; accuracy = 0.94; reward = 200.0\n",
      "num_episodes: 100; seed: 4\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 3s 168us/step - loss: 0.4506 - acc: 0.8123\n",
      "(4) loss = 0.451; accuracy = 0.81; reward = 142.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.3096 - acc: 0.8368\n",
      "(4) loss = 0.310; accuracy = 0.84; reward = 176.7\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 49us/step - loss: 0.2836 - acc: 0.8509\n",
      "(4) loss = 0.284; accuracy = 0.85; reward = 196.7\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.2665 - acc: 0.8638\n",
      "(4) loss = 0.266; accuracy = 0.86; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.2502 - acc: 0.8783\n",
      "(4) loss = 0.250; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 52us/step - loss: 0.2445 - acc: 0.8801\n",
      "(4) loss = 0.244; accuracy = 0.88; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 46us/step - loss: 0.2323 - acc: 0.8971\n",
      "(4) loss = 0.232; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.2272 - acc: 0.8949\n",
      "(4) loss = 0.227; accuracy = 0.89; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.2171 - acc: 0.9009\n",
      "(4) loss = 0.217; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.2167 - acc: 0.9017\n",
      "(4) loss = 0.217; accuracy = 0.90; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.2146 - acc: 0.9064\n",
      "(4) loss = 0.215; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.2194 - acc: 0.9052\n",
      "(4) loss = 0.219; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.2063 - acc: 0.9123\n",
      "(4) loss = 0.206; accuracy = 0.91; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.2060 - acc: 0.9204\n",
      "(4) loss = 0.206; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 53us/step - loss: 0.1892 - acc: 0.9233\n",
      "(4) loss = 0.189; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 46us/step - loss: 0.1910 - acc: 0.9241\n",
      "(4) loss = 0.191; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 46us/step - loss: 0.1871 - acc: 0.9248\n",
      "(4) loss = 0.187; accuracy = 0.92; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 50us/step - loss: 0.1913 - acc: 0.9263\n",
      "(4) loss = 0.191; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.1828 - acc: 0.9288\n",
      "(4) loss = 0.183; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.1842 - acc: 0.9317\n",
      "(4) loss = 0.184; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.1751 - acc: 0.9357\n",
      "(4) loss = 0.175; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 43us/step - loss: 0.1757 - acc: 0.9338\n",
      "(4) loss = 0.176; accuracy = 0.93; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.1704 - acc: 0.9369\n",
      "(4) loss = 0.170; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 48us/step - loss: 0.1709 - acc: 0.9393\n",
      "(4) loss = 0.171; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 51us/step - loss: 0.1717 - acc: 0.9424\n",
      "(4) loss = 0.172; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 45us/step - loss: 0.1659 - acc: 0.9429\n",
      "(4) loss = 0.166; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.1608 - acc: 0.9482\n",
      "(4) loss = 0.161; accuracy = 0.95; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 44us/step - loss: 0.1565 - acc: 0.9444\n",
      "(4) loss = 0.157; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 50us/step - loss: 0.1664 - acc: 0.9450\n",
      "(4) loss = 0.166; accuracy = 0.94; reward = 200.0\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 1s 51us/step - loss: 0.1620 - acc: 0.9479\n",
      "(4) loss = 0.162; accuracy = 0.95; reward = 200.0\n"
     ]
    }
   ],
   "source": [
    "random_seeds = 5\n",
    "# Dictionary mapping number of expert trajectories to a list of rewards.\n",
    "# Each is the result of running with a different random seed.\n",
    "reward_data = OrderedDict({  \n",
    "    1: [],\n",
    "    10: [],\n",
    "    50: [],\n",
    "    100: []\n",
    "})\n",
    "accuracy_data = OrderedDict({  \n",
    "    1: [],\n",
    "    10: [],\n",
    "    50: [],\n",
    "    100: []\n",
    "})\n",
    "loss_data = OrderedDict({  \n",
    "    1: [],\n",
    "    10: [],\n",
    "    50: [],\n",
    "    100: []\n",
    "})\n",
    "\n",
    "mode = 'behavior cloning'\n",
    "# mode = 'dagger'\n",
    "\n",
    "for num_episodes in [1, 10, 50, 100]:#\n",
    "  loss_vec = []\n",
    "  acc_vec = []\n",
    "  imitation_reward_vec = []\n",
    "  for t in range(random_seeds):\n",
    "    print('num_episodes: %s; seed: %d' % (num_episodes, t))\n",
    "    \n",
    "    # WRITE CODE HERE\n",
    "    # Hint: The code here should be nearly identical to code after the\n",
    "    # \"Student vs Expert\" cell. Feel free to copy and paste.\n",
    "    seed(t)\n",
    "    set_random_seed(t)\n",
    "    env = gym.make('CartPole-v0')\n",
    "    env.seed(t)\n",
    "\n",
    "    \n",
    "    num_iterations = 30  # Number of training iterations. Use a small number\n",
    "                     # (e.g., 10) for debugging, and then try a larger number\n",
    "                     # (e.g., 100).\n",
    "    \n",
    "    im = Imitation(env, num_episodes)\n",
    "    loss_vec_seed =[]\n",
    "    acc_vec_seed = []\n",
    "    imitation_reward_vec_seed = []\n",
    "    for i in range(num_iterations):\n",
    "      if mode == 'behavior cloning':\n",
    "        im.generate_behavior_cloning_data()\n",
    "      elif mode == 'dagger':\n",
    "        im.generate_dagger_data()\n",
    "      else:\n",
    "        raise ValueError('Unknown mode: %s' % mode)\n",
    "        \n",
    "      loss, acc = im.train(num_epochs=1)\n",
    "      imitation_reward = im.evaluate(im.model)\n",
    "      loss_vec_seed.append(loss)\n",
    "      acc_vec_seed.append(acc)\n",
    "      imitation_reward_vec_seed.append(imitation_reward)\n",
    "      print('(%d) loss = %.3f; accuracy = %.2f; reward = %.1f' % (t, loss, acc, imitation_reward))\n",
    "    loss_vec.append(loss_vec_seed)\n",
    "    acc_vec.append(acc_vec_seed)\n",
    "    imitation_reward_vec.append(imitation_reward_vec_seed)\n",
    "    \n",
    "\n",
    "  reward_data[num_episodes] = np.mean(np.array(imitation_reward_vec),axis=0)\n",
    "  accuracy_data[num_episodes] = np.mean(np.array(acc_vec),axis=0)\n",
    "  loss_data[num_episodes] = np.mean(np.array(loss_vec),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ec4HEd163il1"
   },
   "source": [
    "Plot the reward, loss, and accuracy for each, remembering to label each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "iQzT0nPc5Odm",
    "outputId": "02838105-8c4c-4193-8a75-ad5e79504bd1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtwAAAEPCAYAAABx6xN1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncIuIiIiI5ND/A8dOuDXscmBTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keys = [1, 10, 50, 100]\n",
    "plt.figure(figsize=(12, 4))\n",
    "# print(reward_data[1])\n",
    "for (index, (data, name)) in enumerate(zip([reward_data, accuracy_data, loss_data],\n",
    "                                           ['reward', 'accuracy', 'loss'])):\n",
    "\n",
    "  plt.subplot(1, 3, index + 1)\n",
    "#   plt.plot(data.keys(), data.values(), '-o')\n",
    "\n",
    "\n",
    "  for key in data.keys():\n",
    "    plt.plot(data[key], '-o')\n",
    "\n",
    "\n",
    "  plt.xlabel('Num Iterations', fontsize=16)\n",
    "  plt.ylabel(name, fontsize=16)\n",
    "  plt.legend(['1','10','50','100'])\n",
    "plt.savefig('expert_data_%s.png' % mode, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l12OnOMTL214"
   },
   "source": [
    "## Problem 2: CMA-ES (25 pt)\n",
    "In this section, you will implement CMA-ES, a black-box optimization algorithm. You will then use CMA-ES to solve a reinforcement learning problem. In particular, the function you will maximize is\n",
    "$$\\max_\\theta J(\\theta) = E_{\\pi_\\theta} \\left[ \\sum_t r(s_t, a_t) \\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jdGOCHD6NZsr"
   },
   "outputs": [],
   "source": [
    "class CMAES:\n",
    "    def __init__(self, env, L, n, p, sigma, noise, reward_fn=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          env: environment with which to evaluate different weights\n",
    "          L: number of episodes used to evaluate a given set of weights\n",
    "          n: number of members (weights) in each generation\n",
    "          p: proportion of members used to update the mean and covariance\n",
    "          sigma: initial std\n",
    "          noise: additional noise to add to covariance\n",
    "          reward_fn: if specified, this reward function is used instead of the \n",
    "            default environment reward. This will be used in Problem 3, when the\n",
    "            reward function will come from the discriminator. The reward\n",
    "            function should be a function of the state and action.\n",
    "        \"\"\"\n",
    "\n",
    "        self.env = env\n",
    "        self.model = make_model(self.env.observation_space.shape[0])\n",
    "        # Let d be the dimension of the 1d vector of weights.\n",
    "        self.d = sum(int(np.product(w.shape)) for w in self.model.weights)\n",
    "        self.mu = np.zeros(self.d)\n",
    "        self.S = sigma**2 * np.eye(self.d)\n",
    "\n",
    "        self.L = L\n",
    "        self.n = n\n",
    "        self.p = p\n",
    "        self.noise = noise\n",
    "        self.reward_fn = reward_fn\n",
    "\n",
    "\n",
    "    def populate(self):\n",
    "        \"\"\"\n",
    "        Populate a generation using the current estimates of mu and S\n",
    "        \"\"\"\n",
    "        self.population = []\n",
    "        # WRITE CODE HERE\n",
    "        self.population = np.random.multivariate_normal(self.mu,self.S,self.n)\n",
    "        \n",
    "\n",
    "    def set_weight(self, member):\n",
    "        ind = 0\n",
    "        weights = []\n",
    "        for w in self.model.weights:\n",
    "          if len(w.shape) > 1:\n",
    "            mat = member[ind:ind+int(w.shape[0]*w.shape[1])]\n",
    "            mat = np.reshape(mat, w.shape)\n",
    "            ind += int(w.shape[0]*w.shape[1])\n",
    "          else:\n",
    "            mat = member[ind:ind+int(w.shape[0])]\n",
    "            ind += int(w.shape[0])\n",
    "          weights.append(mat)\n",
    "\n",
    "        self.model.set_weights(weights)\n",
    "        \n",
    "\n",
    "    def evaluate(self, member, num_episodes):\n",
    "        \"\"\"\n",
    "        Evaluate a set of weights by interacting with the environment and\n",
    "        return the average total reward over num_episodes.\n",
    "        \"\"\"\n",
    "        self.set_weight(member)\n",
    "        return self.evaluate_policy(self.model, num_episodes)\n",
    "    \n",
    "    def evaluate_policy(self, policy, num_episodes):\n",
    "        episode_rewards = []\n",
    "        # WRITE CODE HERE\n",
    "        for episode in range(num_episodes):\n",
    "          states, actions, rewards = generate_episode(self.env, policy)\n",
    "          if(self.reward_fn):\n",
    "            rewards = np.array([self.reward_fn(s,0) for s in states])\n",
    "          episode_rewards.append(np.sum(rewards))\n",
    "          \n",
    "        return np.mean(episode_rewards)\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Perform an iteration of CMA-ES by evaluating all members of the\n",
    "        current population and then updating mu and S with the top self.p\n",
    "        proportion of members. Note that self.populate automatically deletes\n",
    "        all the old members, so you don't need to worry about deleting the\n",
    "        \"bad\" members.\n",
    "\n",
    "        \"\"\"\n",
    "        self.populate()\n",
    "        #WRITE CODE HERE\n",
    "\n",
    "        best_member = []\n",
    "        rewards = []\n",
    "\n",
    "        for member in self.population:\n",
    "          r = self.evaluate(member,self.L) # L = num episodes\n",
    "          rewards.append(r)\n",
    "          \n",
    "        top_ids = np.argsort(rewards)[-int(self.p*self.n):]\n",
    "\n",
    "        self.mu = np.mean(self.population[top_ids],axis=0)\n",
    "\n",
    "        self.S = np.cov(self.population[top_ids].T) + self.noise*np.eye(self.d)\n",
    "        best_member = self.population[top_ids[-1]]\n",
    "        best_r = self.evaluate(best_member, 10)\n",
    "        mu_r   = self.evaluate(self.mu, 10)\n",
    "        \n",
    "        return mu_r, best_r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "colab_type": "code",
    "id": "tzbc2TqJNk-I",
    "outputId": "dc619894-c1c2-4b5a-c247-9c33b715f834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population size: 50\n",
      "(0) avg member rew = 11.50; best member rew = 31.40\n",
      "(1) avg member rew = 9.70; best member rew = 148.40\n",
      "(2) avg member rew = 10.30; best member rew = 105.90\n",
      "(3) avg member rew = 21.10; best member rew = 161.00\n",
      "(4) avg member rew = 17.20; best member rew = 188.20\n",
      "(5) avg member rew = 133.10; best member rew = 171.70\n",
      "(6) avg member rew = 160.70; best member rew = 174.00\n",
      "(7) avg member rew = 164.40; best member rew = 163.50\n",
      "(8) avg member rew = 143.60; best member rew = 159.40\n",
      "(9) avg member rew = 150.60; best member rew = 173.20\n",
      "(10) avg member rew = 149.70; best member rew = 163.10\n",
      "(11) avg member rew = 156.90; best member rew = 182.30\n"
     ]
    }
   ],
   "source": [
    "iterations = 200  # Use 10 for debugging, and then try 200 once you've got it working.\n",
    "pop_size_vec = [50]             # Start with a population size of 50. Once that\n",
    "# pop_size_vec = [20, 50, 100]  # works, try varying the population size.\n",
    "                              \n",
    "data = {pop_size: [] for pop_size in pop_size_vec}\n",
    "\n",
    "for pop_size in pop_size_vec:\n",
    "  print('Population size:', pop_size)\n",
    "  env = gym.make('CartPole-v0')\n",
    "  optimizer = CMAES(env,\n",
    "                    L=1,  # number of episodes for evaluation\n",
    "                    n=pop_size,  # population size\n",
    "                    p=0.25,  # proportion of population to keep\n",
    "                    sigma=10,  # initial std dev\n",
    "                    noise=0.25)  # noise\n",
    "\n",
    "  for t in range(iterations):\n",
    "      mu_r, best_r = optimizer.train()\n",
    "      data[pop_size].append((mu_r, best_r))\n",
    "      print('(%d) avg member rew = %.2f; best member rew = %.2f' % (t, mu_r, best_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcFCtckj-2qc"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(121)  # Left plot will show performance vs number of iterations\n",
    "for pop_size, values in data.items():\n",
    "  mu_r = np.array(values)[:, 0]  # Use the performance of the best point\n",
    "  best_r = np.array(values)[:, 1]\n",
    "  x = np.arange(len(mu_r)) + 1\n",
    "  plt.plot(x, mu_r, label=str(pop_size))\n",
    "  plt.plot(x, best_r, label=str(pop_size))\n",
    "  \n",
    "  plt.ylabel('return', fontsize=16)\n",
    "  plt.xlabel('num. iterations', fontsize=16)\n",
    "  plt.legend([\"mu_r\",\"best_r\"])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cmaes_pop_size_1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "kiL2DqEEjZ2i",
    "outputId": "e561923d-3d2a-4ef9-e903-9134d1c3e4d1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAEYCAYAAABBWFftAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(121)  # Left plot will show performance vs number of iterations\n",
    "for pop_size, values in data.items():\n",
    "  best_r = np.array(values)[:, 1]  # Use the performance of the best point\n",
    "  x = np.arange(len(best_r)) + 1\n",
    "  plt.plot(x, best_r, label=str(pop_size))\n",
    "  plt.ylabel('Best return', fontsize=16)\n",
    "  plt.xlabel('num. iterations', fontsize=16)\n",
    "\n",
    "plt.subplot(122)  # Right plot will show performance vs number of points evaluated\n",
    "for pop_size, values in data.items():\n",
    "  best_r = np.array(values)[:, 1]  # Use the performance of the best point\n",
    "  x = pop_size * (np.arange(len(best_r)) + 1)\n",
    "  plt.plot(x, best_r, label=str(pop_size))\n",
    "  plt.ylabel('Best return', fontsize=16)\n",
    "  plt.xlabel('num. points evaluated', fontsize=16)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('cmaes_pop_size.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fEYzLBqXL6e-"
   },
   "source": [
    "## Problem 3: GAIL (25 pt)\n",
    "For this problem, we will only condition the discriminator on the state, not the action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XvQ0lfe4L8b2"
   },
   "outputs": [],
   "source": [
    "class GAIL(object):\n",
    "  \n",
    "  def __init__(self, env):\n",
    "    self.env = env\n",
    "    self.expert = tf.keras.models.load_model('expert.h5')\n",
    "#     self.model = make_model()\n",
    "    self.discriminator = make_model(self.env.observation_space.shape[0])\n",
    "    print(\"init\",self._reward_fn)\n",
    "    self.cmaes = CMAES(env,\n",
    "                  L=1,  # number of episodes for evaluation\n",
    "                  n=20,  # population size\n",
    "                  p=0.25,  # proportion of population to keep\n",
    "                  sigma=10,  # initial std dev\n",
    "                  noise=0.25,  # noise\n",
    "                  reward_fn=self._reward_fn)\n",
    "    self.expert_states = []\n",
    "    self.student_states = []\n",
    "    \n",
    "  def _reward_fn(self, s, a):\n",
    "    \"\"\"Log probability that state is from expert.\"\"\"\n",
    "    del a\n",
    "    p_expert = self.discriminator.predict(s[None])[0][0]    \n",
    "    return np.log(p_expert+1)\n",
    "    \n",
    "  def collect_data(self, num_episodes):\n",
    "    \"\"\"Collect data from the expert and imitation policy. After the initial\n",
    "    iteration, there is no need to collect new data from the expert, as the\n",
    "    expert policy never changes.\n",
    "    \"\"\"\n",
    "    collect_expert = len(self.expert_states) == 0\n",
    "    self.student_states = []\n",
    "    for _ in range(num_episodes):\n",
    "      # WRITE CODE HERE\n",
    "      # Collect data from the expert policy\n",
    "      # Collect data from the student policy\n",
    "      if(collect_expert):\n",
    "        states_exp,actions_exp,rewards_exp = generate_episode(self.env,self.expert)\n",
    "        self.expert_states.extend(states_exp)\n",
    "      \n",
    "      states_stu,actions_stu,rewards_stu = generate_episode(self.env,self.cmaes.model)      \n",
    "      self.student_states.extend(states_stu)\n",
    "      \n",
    "    pass\n",
    "  \n",
    "  def train_discriminator(self,num_episodes):\n",
    "    # WRITE CODE HERE\n",
    "    \n",
    "    self.collect_data(num_episodes)\n",
    "    X = np.concatenate((self.expert_states,self.student_states),axis=0)\n",
    "    Y = np.zeros(shape=(X.shape[0],1),dtype=np.int32)\n",
    "    Y[len(self.expert_states):,0] = 1\n",
    "    \n",
    "    Y = np.array([disc_action_to_one_hot(2,y) for y in Y])    \n",
    "    idxs  = np.arange(0,X.shape[0])\n",
    "#     np.random.shuffle(idxs)\n",
    "    assert Y.shape[1] == 2  # Use a 1-hot encoding for the labels\n",
    "    assert np.all(np.sum(Y, axis=1) == 1)\n",
    "    history = self.discriminator.fit(X, Y, epochs=10, batch_size=256, verbose=0)\n",
    "    loss = history.history['loss'][-1]\n",
    "    acc = history.history['acc'][-1]\n",
    "    return loss, acc\n",
    "  \n",
    "  def train_policy(self):\n",
    "    mu_r, best_r = self.cmaes.train()\n",
    "    return mu_r, best_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hewr6Ek4Fx6r"
   },
   "outputs": [],
   "source": [
    "### Implement the total variation distance to compare two policies\n",
    "def get_x_position_histogram(states):\n",
    "  x_vec = [s[0] for s in states]  # The x position is the first coordinate\n",
    "  bins = np.linspace(-2.4, 2.4, 11)  # Need 11 edges to make 10 bins\n",
    "  hist, _ = np.histogram(x_vec, bins=bins, density=True)\n",
    "  return hist\n",
    "\n",
    "def TV_distance(expert_states, student_states):\n",
    "  expert_hist = get_x_position_histogram(expert_states)\n",
    "  student_hist = get_x_position_histogram(student_states)\n",
    "  return 0.5 * np.sum(np.abs(expert_hist - student_hist))\n",
    "\n",
    "\n",
    "def evaluate(gail):\n",
    "  \"\"\"Evaluate the policy learned by GAIL according to three metrics:\n",
    "    1. Environment reward. We want this number to be large (~100)\n",
    "    2. How well it fools the discriminator. In particular, we compute the\n",
    "      discriminator's prediction that the policy is the expert. The policy\n",
    "      tries to increase this number, while the discriminator tries to decrease\n",
    "      it. We expect it to be around 40% - 60%\n",
    "    3. Total variation distance between the student and the expert, along the\n",
    "      X axis. We want this number to be small (~0).\"\"\"\n",
    "  rewards_vec = []\n",
    "  p_expert_vec = []\n",
    "  for _ in range(10):\n",
    "    states, actions, rewards = generate_episode(gail.env, gail.cmaes.model)\n",
    "    rewards_vec.append(np.sum(rewards))\n",
    "    log_p_expert = [gail._reward_fn(s, a) for (s, a) in zip(states, actions)]\n",
    "    p_expert = np.exp(log_p_expert)\n",
    "    p_expert_vec.append(np.mean(p_expert))\n",
    "  tv_dist = TV_distance(gail.expert_states, gail.student_states)\n",
    "  return np.mean(p_expert_vec), np.mean(rewards_vec), tv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xDbeWwvQI5FG"
   },
   "outputs": [],
   "source": [
    "discriminator_update_period = 10\n",
    "num_episodes = 10\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "gail = GAIL(env)\n",
    "disc_only_acc = []\n",
    "for t in range(100):\n",
    "  # WRITE CODE HERE\n",
    "  loss,acc = gail.train_discriminator(num_episodes)\n",
    "  disc_only_acc.append(acc)\n",
    "  print(\"loss,acc:\" ,loss,acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JtvqCg8bISsR"
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "  mu_r,best_r = gail.train_policy()\n",
    "  \n",
    "  \n",
    "# #   p_expert, avg_r, tv_dist = evaluate(gail)\n",
    "\n",
    "# # plt.plot(disc_only_acc)  \n",
    "#   print('(%d) Policy: p(expert) = %.2f%% ; reward = %.1f' % (t, 100.0 * p_expert, avg_r))\n",
    "#   print('(%d) Total variation distance = %.2f' % (t, tv_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9VsokbidIUI2"
   },
   "outputs": [],
   "source": [
    "# plt.plot(disc_only_acc)\n",
    "# plt.xlabel(\"num_of_steps\")\n",
    "# plt.ylabel(\"accuracy\")\n",
    "# plt.savefig(\"Accuracy_q3_1.png\")\n",
    "tv_dists = []\n",
    "task_reward = []\n",
    "for t in range(5):\n",
    "  mu_r,best_r = gail.train_policy()\n",
    "  _ , r , tv_dist = evaluate(gail)\n",
    "  tv_dists.append(tv_dist)\n",
    "  task_reward.append(r)\n",
    "\n",
    "  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SHaHFxDVIVxO"
   },
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "plt.plot(tv_dists)\n",
    "plt.xlabel(\"num_of_steps\")\n",
    "plt.ylabel(\"tv_dists\")\n",
    "plt.show()\n",
    "\n",
    "fig2 = plt.figure()\n",
    "plt.plot(task_reward)\n",
    "plt.xlabel(\"num_of_steps\")\n",
    "plt.ylabel(\"task_reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jVeqRhMDgPqW"
   },
   "source": [
    "# You're Done!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
